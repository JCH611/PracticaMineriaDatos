{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificacion Baggins\n",
    "Para probar el clasificador con baggins vamos a utilizar las dos técnicas de selección de características y de reducción de instancias que mejor nos han funcionado en el apartado anterior:\n",
    "- mrMr con centroides soft\n",
    "- RFC con centroides soft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos cargados exitosamente:\n",
      "train_data: (256326, 31)\n",
      "df_reduce_mrmr: (256326, 11)\n",
      "df_reduce_mrmr_instances: (886, 11)\n",
      "df_reduce_mrmr_instances_GLVQ: (2, 11)\n",
      "df_X_train_reduce_RFC: (256326, 11)\n",
      "df_reduce_RFC_instances: (886, 11)\n",
      "df_reduce_RFC_instances_GLVQ: (2, 11)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_path = './data/'\n",
    "\n",
    "\n",
    "train_data = pd.read_csv(f'{data_path}train_data.csv')\n",
    "test_data = pd.read_csv(f'{data_path}test_data.csv')\n",
    "\n",
    "# Selección de características con mrMr\n",
    "df_reduce_mrmr = pd.read_csv(f'{data_path}X_train_reduce_mrmr.csv')\n",
    "df_reduce_mrmr_instances = pd.read_csv(f'{data_path}df_reduce_mrmr_instances.csv')\n",
    "df_reduce_mrmr_instances_hard = pd.read_csv(f'{data_path}df_reduce_mrmr_instances_hard.csv')\n",
    "df_reduce_mrmr_instances_GLVQ = pd.read_csv(f'{data_path}df_reduce_mrmr_instances_GLVQ.csv')\n",
    "\n",
    "# Selección de características con RFC\n",
    "df_X_train_reduce_RFC = pd.read_csv(f'{data_path}df_X_train_reduce_RFC.csv')\n",
    "df_reduce_RFC_instances = pd.read_csv(f'{data_path}df_reduce_RFC_instances.csv')\n",
    "df_reduce_RFC_instances_hard = pd.read_csv(f'{data_path}df_reduce_RFC_instances_hard.csv')\n",
    "df_reduce_RFC_instances_GLVQ = pd.read_csv(f'{data_path}df_reduce_RFC_instances_GLVQ.csv')\n",
    "\n",
    "# Mostrar información sobre los DataFrames cargados\n",
    "print(\"Datos cargados exitosamente:\")\n",
    "print(f\"train_data: {train_data.shape}\")\n",
    "print(f\"df_reduce_mrmr: {df_reduce_mrmr.shape}\")\n",
    "print(f\"df_reduce_mrmr_instances: {df_reduce_mrmr_instances.shape}\")\n",
    "print(f\"df_reduce_mrmr_instances_GLVQ: {df_reduce_mrmr_instances_GLVQ.shape}\")\n",
    "print(f\"df_X_train_reduce_RFC: {df_X_train_reduce_RFC.shape}\")\n",
    "print(f\"df_reduce_RFC_instances: {df_reduce_RFC_instances.shape}\")\n",
    "print(f\"df_reduce_RFC_instances_GLVQ: {df_reduce_RFC_instances_GLVQ.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baggins con mrMr clusterCentroids_soft\n",
    "\n",
    "#### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones de los conjuntos:\n",
      "Conjunto de entrenamiento: (708, 10), (708,)\n",
      "Conjunto de prueba: (178, 10), (178,)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mbagging, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Ajusta el modelo a los datos de entrenamiento\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Imprime los mejores parámetros y su desempeño\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMejores parámetros:\u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_search\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[0;32m~/Master/mineriaDeDatosPreprocesamientoYClasificacion/PracticaMineriaDatos/.venv/lib/python3.10/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Master/mineriaDeDatosPreprocesamientoYClasificacion/PracticaMineriaDatos/.venv/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1024\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1018\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1019\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1020\u001b[0m     )\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1024\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1028\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Master/mineriaDeDatosPreprocesamientoYClasificacion/PracticaMineriaDatos/.venv/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1571\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1570\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1571\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Master/mineriaDeDatosPreprocesamientoYClasificacion/PracticaMineriaDatos/.venv/lib/python3.10/site-packages/sklearn/model_selection/_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    963\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    965\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    966\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    967\u001b[0m         )\n\u001b[1;32m    968\u001b[0m     )\n\u001b[0;32m--> 970\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    990\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    993\u001b[0m     )\n",
      "File \u001b[0;32m~/Master/mineriaDeDatosPreprocesamientoYClasificacion/PracticaMineriaDatos/.venv/lib/python3.10/site-packages/sklearn/utils/parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     76\u001b[0m )\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Master/mineriaDeDatosPreprocesamientoYClasificacion/PracticaMineriaDatos/.venv/lib/python3.10/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Master/mineriaDeDatosPreprocesamientoYClasificacion/PracticaMineriaDatos/.venv/lib/python3.10/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Master/mineriaDeDatosPreprocesamientoYClasificacion/PracticaMineriaDatos/.venv/lib/python3.10/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X = df_reduce_mrmr_instances.drop(columns=['Class'])\n",
    "y = df_reduce_mrmr_instances['Class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "print(\"Dimensiones de los conjuntos:\")\n",
    "print(f\"Conjunto de entrenamiento: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Conjunto de prueba: {X_test.shape}, {y_test.shape}\")\n",
    "\n",
    "base_estimator = DecisionTreeClassifier()\n",
    "bagging = BaggingClassifier(estimator=base_estimator, random_state=0)\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 20, 50, 100],  \n",
    "    'max_samples': [0.5, 0.7, 1.0],    \n",
    "    'max_features': [0.5, 0.7, 1.0],   \n",
    "    'bootstrap': [True, False],        \n",
    "    'bootstrap_features': [True, False] \n",
    "}\n",
    "\n",
    "# Configura el GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=bagging, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Ajusta el modelo a los datos de entrenamiento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Imprime los mejores parámetros y su desempeño\n",
    "print(\"Mejores parámetros:\", grid_search.best_params_)\n",
    "print(\"Mejor puntuación de validación cruzada:\", grid_search.best_score_)\n",
    "\n",
    "# Evalúa el mejor modelo en los datos de prueba\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(\"Informe completo en datos de prueba\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMPROBAMOS EL RESULTADO CON EL CONJUNTO DE TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "0    28432\n",
      "1       49\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_63839/3588149006.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_reduce['Amount'] = scaler.fit_transform(X_reduce[['Amount']])\n",
      "/tmp/ipykernel_63839/3588149006.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_reduce['Time'] = scaler.fit_transform(X_reduce[['Time']])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Cogemos los datos de test y les eliminamos las cracterísticas que no necesitamos\n",
    "X = test_data.drop(columns=['Class'])\n",
    "y_test_final = test_data['Class']\n",
    "columns_to_keep_mrmr = ['V17', 'Time', 'Amount', 'V25', 'V20', 'V7', 'V13', 'V22', 'V19', 'V23']\n",
    "X_reduce = X[columns_to_keep_mrmr]\n",
    "\n",
    "\n",
    "#normalizamos la entrada\n",
    "scaler = MinMaxScaler()\n",
    "# Normalizar las columnas\n",
    "X_reduce['Amount'] = scaler.fit_transform(X_reduce[['Amount']])\n",
    "X_reduce['Time'] = scaler.fit_transform(X_reduce[['Time']])\n",
    "\n",
    "print(y_test_final.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión:\n",
      "[[14303 14129]\n",
      " [    2    47]]\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Correctas       1.00      0.50      0.67     28432\n",
      "Fraudulentas       0.00      0.96      0.01        49\n",
      "\n",
      "    accuracy                           0.50     28481\n",
      "   macro avg       0.50      0.73      0.34     28481\n",
      "weighted avg       1.00      0.50      0.67     28481\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Configura el modelo con los mejores parámetros\n",
    "bagging_best = BaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(),  \n",
    "    n_estimators=50,                     \n",
    "    max_samples=0.7,                     \n",
    "    max_features=1.0,                   \n",
    "    bootstrap=False,\n",
    "    bootstrap_features=True,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "X = df_reduce_mrmr_instances.drop(columns=['Class'])\n",
    "y = df_reduce_mrmr_instances['Class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Entrena el modelo con los datos de entrenamiento\n",
    "bagging_best.fit(X_train, y_train)\n",
    "\n",
    "# Evalúa el modelo en los datos de prueba\n",
    "y_pred_dtc = bagging_best.predict(X_reduce)\n",
    "\n",
    "# Calcular la matriz de confusión\n",
    "conf_matrix = confusion_matrix(y_test_final, y_pred_dtc)\n",
    "report = classification_report(y_test_final, y_pred_dtc, target_names=['Correctas', 'Fraudulentas'])\n",
    "# Mostrar la matriz de confusión\n",
    "print(\"Matriz de confusión:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"Reporte de Clasificación:\")\n",
    "print(report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones de los conjuntos:\n",
      "Conjunto de entrenamiento: (708, 10), (708,)\n",
      "Conjunto de prueba: (178, 10), (178,)\n",
      "Mejores parámetros: {'bootstrap': False, 'bootstrap_features': True, 'max_features': 0.5, 'max_samples': 1.0, 'n_estimators': 10}\n",
      "Mejor puntuación de validación cruzada: 0.8757067226051344\n",
      "Informe completo en datos de prueba\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.98      0.87        89\n",
      "           1       0.97      0.74      0.84        89\n",
      "\n",
      "    accuracy                           0.86       178\n",
      "   macro avg       0.88      0.86      0.86       178\n",
      "weighted avg       0.88      0.86      0.86       178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.svm import SVC\n",
    "X = df_reduce_mrmr_instances.drop(columns=['Class'])\n",
    "y = df_reduce_mrmr_instances['Class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "print(\"Dimensiones de los conjuntos:\")\n",
    "print(f\"Conjunto de entrenamiento: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Conjunto de prueba: {X_test.shape}, {y_test.shape}\")\n",
    "\n",
    "base_estimator = SVC(probability=True)\n",
    "bagging = BaggingClassifier(estimator=base_estimator, random_state=0)\n",
    "\n",
    "# Configura el GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=bagging, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Ajusta el modelo a los datos de entrenamiento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Imprime los mejores parámetros y su desempeño\n",
    "print(\"Mejores parámetros:\", grid_search.best_params_)\n",
    "print(\"Mejor puntuación de validación cruzada:\", grid_search.best_score_)\n",
    "\n",
    "# Evalúa el mejor modelo en los datos de prueba\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(\"Informe completo en datos de prueba\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     param_bootstrap  param_bootstrap_features  param_max_features  \\\n",
      "0               True                      True                 0.5   \n",
      "1               True                      True                 0.5   \n",
      "2               True                      True                 0.5   \n",
      "3               True                      True                 0.5   \n",
      "4               True                      True                 0.5   \n",
      "..               ...                       ...                 ...   \n",
      "139            False                     False                 1.0   \n",
      "140            False                     False                 1.0   \n",
      "141            False                     False                 1.0   \n",
      "142            False                     False                 1.0   \n",
      "143            False                     False                 1.0   \n",
      "\n",
      "     param_max_samples  param_n_estimators  mean_test_score  \n",
      "0                  0.5                  10         0.867226  \n",
      "1                  0.5                  20         0.860174  \n",
      "2                  0.5                  50         0.860154  \n",
      "3                  0.5                 100         0.855928  \n",
      "4                  0.7                  10         0.871461  \n",
      "..                 ...                 ...              ...  \n",
      "139                0.7                 100         0.857337  \n",
      "140                1.0                  10         0.862991  \n",
      "141                1.0                  20         0.862991  \n",
      "142                1.0                  50         0.862991  \n",
      "143                1.0                 100         0.862991  \n",
      "\n",
      "[144 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Extrae los resultados del GridSearchCV\n",
    "results = grid_search.cv_results_\n",
    "\n",
    "# Crea un DataFrame con los resultados de los parámetros y las puntuaciones\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# Muestra solo las columnas de interés: los parámetros y las puntuaciones de test\n",
    "df_results_filtered = df_results[['param_{0}'.format(param) for param in results['params'][0].keys()] + ['mean_test_score']]\n",
    "\n",
    "# Muestra la matriz de resultados\n",
    "print(df_results_filtered)\n",
    "\n",
    "df_results_filtered.to_csv('./data/df_results_filtered.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMPROBAMOS EL RESULTADO CON EL CONJUNTO DE TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión:\n",
      "[[28282   150]\n",
      " [    7    42]]\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Correctas       1.00      0.99      1.00     28432\n",
      "Fraudulentas       0.22      0.86      0.35        49\n",
      "\n",
      "    accuracy                           0.99     28481\n",
      "   macro avg       0.61      0.93      0.67     28481\n",
      "weighted avg       1.00      0.99      1.00     28481\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# Configura el modelo con los mejores parámetros\n",
    "bagging_best = BaggingClassifier(\n",
    "    estimator=SVC(probability=True),  \n",
    "    n_estimators=10,                     \n",
    "    max_samples=1.0,                     \n",
    "    max_features=0.5,                   \n",
    "    bootstrap=False,\n",
    "    bootstrap_features=True,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "X = df_reduce_mrmr_instances.drop(columns=['Class'])\n",
    "y = df_reduce_mrmr_instances['Class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Entrena el modelo con los datos de entrenamiento\n",
    "bagging_best.fit(X_train, y_train)\n",
    "\n",
    "# Evalúa el modelo en los datos de prueba\n",
    "y_pred_svc = bagging_best.predict(X_reduce)\n",
    "\n",
    "# Calcular la matriz de confusión\n",
    "conf_matrix = confusion_matrix(y_test_final, y_pred_svc)\n",
    "report = classification_report(y_test_final, y_pred_svc, target_names=['Correctas', 'Fraudulentas'])\n",
    "# Mostrar la matriz de confusión\n",
    "print(\"Matriz de confusión:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"Reporte de Clasificación:\")\n",
    "print(report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|            | Predicción: Negativo | Predicción: Positivo |\n",
    "|------------|-----------------------|-----------------------|\n",
    "| **Real: Negativo** | 28282                 | 150                   |\n",
    "| **Real: Positivo** | 7                     | 42                    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones de los conjuntos:\n",
      "Conjunto de entrenamiento: (708, 10), (708,)\n",
      "Conjunto de prueba: (178, 10), (178,)\n",
      "Mejores parámetros: {'bootstrap': True, 'bootstrap_features': True, 'max_features': 0.5, 'max_samples': 0.5, 'n_estimators': 10}\n",
      "Mejor puntuación de validación cruzada: 0.895435021476376\n",
      "Informe completo en datos de prueba\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.75      0.81        89\n",
      "           1       0.78      0.90      0.84        89\n",
      "\n",
      "    accuracy                           0.83       178\n",
      "   macro avg       0.83      0.83      0.82       178\n",
      "weighted avg       0.83      0.83      0.82       178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "X = df_reduce_mrmr_instances.drop(columns=['Class'])\n",
    "y = df_reduce_mrmr_instances['Class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "print(\"Dimensiones de los conjuntos:\")\n",
    "print(f\"Conjunto de entrenamiento: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Conjunto de prueba: {X_test.shape}, {y_test.shape}\")\n",
    "\n",
    "base_estimator = GaussianNB()\n",
    "bagging = BaggingClassifier(estimator=base_estimator, random_state=0)\n",
    "\n",
    "# Configura el GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=bagging, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Ajusta el modelo a los datos de entrenamiento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Imprime los mejores parámetros y su desempeño\n",
    "print(\"Mejores parámetros:\", grid_search.best_params_)\n",
    "print(\"Mejor puntuación de validación cruzada:\", grid_search.best_score_)\n",
    "\n",
    "# Evalúa el mejor modelo en los datos de prueba\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(\"Informe completo en datos de prueba\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMPROBAMOS EL RESULTADO CON EL CONJUNTO DE TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión:\n",
      "[[17420 11012]\n",
      " [    3    46]]\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Correctas       1.00      0.61      0.76     28432\n",
      "Fraudulentas       0.00      0.94      0.01        49\n",
      "\n",
      "    accuracy                           0.61     28481\n",
      "   macro avg       0.50      0.78      0.38     28481\n",
      "weighted avg       1.00      0.61      0.76     28481\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Configura el modelo con los mejores parámetros\n",
    "bagging_best = BaggingClassifier(\n",
    "    estimator=GaussianNB(),  \n",
    "    n_estimators=10,                     \n",
    "    max_samples=0.5,                     \n",
    "    max_features=0.5,                   \n",
    "    bootstrap=True,\n",
    "    bootstrap_features=True,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "X = df_reduce_mrmr_instances.drop(columns=['Class'])\n",
    "y = df_reduce_mrmr_instances['Class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Entrena el modelo con los datos de entrenamiento\n",
    "bagging_best.fit(X_train, y_train)\n",
    "\n",
    "# Evalúa el modelo en los datos de prueba\n",
    "y_pred_gnb = bagging_best.predict(X_reduce)\n",
    "\n",
    "# Calcular la matriz de confusión\n",
    "conf_matrix = confusion_matrix(y_test_final, y_pred_gnb)\n",
    "report = classification_report(y_test_final, y_pred_gnb, target_names=['Correctas', 'Fraudulentas'])\n",
    "# Mostrar la matriz de confusión\n",
    "print(\"Matriz de confusión:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"Reporte de Clasificación:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones de los conjuntos:\n",
      "Conjunto de entrenamiento: (708, 10), (708,)\n",
      "Conjunto de prueba: (178, 10), (178,)\n",
      "Mejores parámetros: {'bootstrap': False, 'bootstrap_features': True, 'max_features': 0.7, 'max_samples': 1.0, 'n_estimators': 100}\n",
      "Mejor puntuación de validación cruzada: 0.963270402557187\n",
      "Informe completo en datos de prueba\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98        89\n",
      "           1       0.99      0.98      0.98        89\n",
      "\n",
      "    accuracy                           0.98       178\n",
      "   macro avg       0.98      0.98      0.98       178\n",
      "weighted avg       0.98      0.98      0.98       178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X = df_reduce_mrmr_instances.drop(columns=['Class'])\n",
    "y = df_reduce_mrmr_instances['Class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "print(\"Dimensiones de los conjuntos:\")\n",
    "print(f\"Conjunto de entrenamiento: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Conjunto de prueba: {X_test.shape}, {y_test.shape}\")\n",
    "\n",
    "base_estimator = RandomForestClassifier()\n",
    "bagging = BaggingClassifier(estimator=base_estimator, random_state=0)\n",
    "\n",
    "# Configura el GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=bagging, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Ajusta el modelo a los datos de entrenamiento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Imprime los mejores parámetros y su desempeño\n",
    "print(\"Mejores parámetros:\", grid_search.best_params_)\n",
    "print(\"Mejor puntuación de validación cruzada:\", grid_search.best_score_)\n",
    "\n",
    "# Evalúa el mejor modelo en los datos de prueba\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(\"Informe completo en datos de prueba\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMPROBAMOS EL RESULTADO CON EL CONJUNTO DE TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión:\n",
      "[[15026 13406]\n",
      " [    2    47]]\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Correctas       1.00      0.53      0.69     28432\n",
      "Fraudulentas       0.00      0.96      0.01        49\n",
      "\n",
      "    accuracy                           0.53     28481\n",
      "   macro avg       0.50      0.74      0.35     28481\n",
      "weighted avg       1.00      0.53      0.69     28481\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Configura el modelo con los mejores parámetros\n",
    "bagging_best = BaggingClassifier(\n",
    "    estimator=RandomForestClassifier(),  \n",
    "    n_estimators=100,                     \n",
    "    max_samples=1.0,                     \n",
    "    max_features=0.7,                   \n",
    "    bootstrap=False,\n",
    "    bootstrap_features=True,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "X = df_reduce_mrmr_instances.drop(columns=['Class'])\n",
    "y = df_reduce_mrmr_instances['Class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Entrena el modelo con los datos de entrenamiento\n",
    "bagging_best.fit(X_train, y_train)\n",
    "\n",
    "# Evalúa el modelo en los datos de prueba\n",
    "y_pred_rfc = bagging_best.predict(X_reduce)\n",
    "\n",
    "# Calcular la matriz de confusión\n",
    "conf_matrix = confusion_matrix(y_test_final, y_pred_rfc)\n",
    "report = classification_report(y_test_final, y_pred_rfc, target_names=['Correctas', 'Fraudulentas'])\n",
    "# Mostrar la matriz de confusión\n",
    "print(\"Matriz de confusión:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"Reporte de Clasificación:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baggins con RFC clusterCentroids_soft\n",
    "\n",
    "#### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones de los conjuntos:\n",
      "Conjunto de entrenamiento: (708, 10), (708,)\n",
      "Conjunto de prueba: (178, 10), (178,)\n",
      "Mejores parámetros: {'bootstrap': False, 'bootstrap_features': True, 'max_features': 1.0, 'max_samples': 0.5, 'n_estimators': 100}\n",
      "Mejor puntuación de validación cruzada: 0.9265507941264609\n",
      "Informe completo en datos de prueba\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.91        89\n",
      "           1       0.95      0.87      0.91        89\n",
      "\n",
      "    accuracy                           0.91       178\n",
      "   macro avg       0.91      0.91      0.91       178\n",
      "weighted avg       0.91      0.91      0.91       178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df_reduce_RFC_instances.drop(columns=['Class'])\n",
    "y = df_reduce_RFC_instances['Class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "print(\"Dimensiones de los conjuntos:\")\n",
    "print(f\"Conjunto de entrenamiento: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Conjunto de prueba: {X_test.shape}, {y_test.shape}\")\n",
    "\n",
    "base_estimator = DecisionTreeClassifier()\n",
    "bagging = BaggingClassifier(estimator=base_estimator, random_state=0)\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 20, 50, 100],  \n",
    "    'max_samples': [0.5, 0.7, 1.0],    \n",
    "    'max_features': [0.5, 0.7, 1.0],   \n",
    "    'bootstrap': [True, False],        \n",
    "    'bootstrap_features': [True, False] \n",
    "}\n",
    "\n",
    "# Configura el GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=bagging, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Ajusta el modelo a los datos de entrenamiento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Imprime los mejores parámetros y su desempeño\n",
    "print(\"Mejores parámetros:\", grid_search.best_params_)\n",
    "print(\"Mejor puntuación de validación cruzada:\", grid_search.best_score_)\n",
    "\n",
    "# Evalúa el mejor modelo en los datos de prueba\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(\"Informe completo en datos de prueba\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMPROBAMOS EL RESULTADO CON EL CONJUNTO DE TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = test_data.drop(columns=['Class'])\n",
    "y_test_final = test_data['Class']\n",
    "### Version con RandomForestClassifier\n",
    "columns_to_keep_RFC = ['V17', 'V16', 'V12', 'V14', 'V11', 'V10', 'V9', 'V4', 'V18', 'V7']\n",
    "X_reduce_RFC = X[columns_to_keep_RFC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión:\n",
      "[[27911   521]\n",
      " [    5    44]]\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Correctas       1.00      0.98      0.99     28432\n",
      "Fraudulentas       0.08      0.90      0.14        49\n",
      "\n",
      "    accuracy                           0.98     28481\n",
      "   macro avg       0.54      0.94      0.57     28481\n",
      "weighted avg       1.00      0.98      0.99     28481\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Configura el modelo con los mejores parámetros\n",
    "bagging_best = BaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(),  \n",
    "    n_estimators=10,                     \n",
    "    max_samples=0.5,                     \n",
    "    max_features=0.5,                   \n",
    "    bootstrap=True,\n",
    "    bootstrap_features=True,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "X = df_reduce_RFC_instances.drop(columns=['Class'])\n",
    "y = df_reduce_RFC_instances['Class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Entrena el modelo con los datos de entrenamiento\n",
    "bagging_best.fit(X_train, y_train)\n",
    "\n",
    "# Evalúa el modelo en los datos de prueba\n",
    "y_pred_rfc = bagging_best.predict(X_reduce_RFC)\n",
    "\n",
    "# Calcular la matriz de confusión\n",
    "conf_matrix = confusion_matrix(y_test_final, y_pred_rfc)\n",
    "report = classification_report(y_test_final, y_pred_rfc, target_names=['Correctas', 'Fraudulentas'])\n",
    "# Mostrar la matriz de confusión\n",
    "print(\"Matriz de confusión:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"Reporte de Clasificación:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones de los conjuntos:\n",
      "Conjunto de entrenamiento: (708, 10), (708,)\n",
      "Conjunto de prueba: (178, 10), (178,)\n",
      "Mejores parámetros: {'bootstrap': True, 'bootstrap_features': False, 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10}\n",
      "Mejor puntuación de validación cruzada: 0.9209169913095595\n",
      "Informe completo en datos de prueba\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.91        89\n",
      "           1       0.96      0.84      0.90        89\n",
      "\n",
      "    accuracy                           0.90       178\n",
      "   macro avg       0.91      0.90      0.90       178\n",
      "weighted avg       0.91      0.90      0.90       178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.svm import SVC\n",
    "X = df_reduce_RFC_instances.drop(columns=['Class'])\n",
    "y = df_reduce_RFC_instances['Class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "print(\"Dimensiones de los conjuntos:\")\n",
    "print(f\"Conjunto de entrenamiento: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Conjunto de prueba: {X_test.shape}, {y_test.shape}\")\n",
    "\n",
    "base_estimator = SVC(probability=True)\n",
    "bagging = BaggingClassifier(estimator=base_estimator, random_state=0)\n",
    "\n",
    "# Configura el GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=bagging, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Ajusta el modelo a los datos de entrenamiento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Imprime los mejores parámetros y su desempeño\n",
    "print(\"Mejores parámetros:\", grid_search.best_params_)\n",
    "print(\"Mejor puntuación de validación cruzada:\", grid_search.best_score_)\n",
    "\n",
    "# Evalúa el mejor modelo en los datos de prueba\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(\"Informe completo en datos de prueba\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMPROBAMOS EL RESULTADO CON EL CONJUNTO DE TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión:\n",
      "[[28253   179]\n",
      " [    5    44]]\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Correctas       1.00      0.99      1.00     28432\n",
      "Fraudulentas       0.20      0.90      0.32        49\n",
      "\n",
      "    accuracy                           0.99     28481\n",
      "   macro avg       0.60      0.95      0.66     28481\n",
      "weighted avg       1.00      0.99      1.00     28481\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Configura el modelo con los mejores parámetros\n",
    "bagging_best = BaggingClassifier(\n",
    "    estimator=SVC(),  \n",
    "    n_estimators=10,                     \n",
    "    max_samples=1.0,                     \n",
    "    max_features=1.0,                   \n",
    "    bootstrap=True,\n",
    "    bootstrap_features=False,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "X = df_reduce_RFC_instances.drop(columns=['Class'])\n",
    "y = df_reduce_RFC_instances['Class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Entrena el modelo con los datos de entrenamiento\n",
    "bagging_best.fit(X_train, y_train)\n",
    "\n",
    "# Evalúa el modelo en los datos de prueba\n",
    "y_pred_rfc = bagging_best.predict(X_reduce_RFC)\n",
    "\n",
    "# Calcular la matriz de confusión\n",
    "conf_matrix = confusion_matrix(y_test_final, y_pred_rfc)\n",
    "report = classification_report(y_test_final, y_pred_rfc, target_names=['Correctas', 'Fraudulentas'])\n",
    "# Mostrar la matriz de confusión\n",
    "print(\"Matriz de confusión:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"Reporte de Clasificación:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones de los conjuntos:\n",
      "Conjunto de entrenamiento: (708, 10), (708,)\n",
      "Conjunto de prueba: (178, 10), (178,)\n",
      "Mejores parámetros: {'bootstrap': False, 'bootstrap_features': True, 'max_features': 1.0, 'max_samples': 0.7, 'n_estimators': 10}\n",
      "Mejor puntuación de validación cruzada: 0.899700329637399\n",
      "Informe completo en datos de prueba\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.98      0.91        89\n",
      "           1       0.97      0.82      0.89        89\n",
      "\n",
      "    accuracy                           0.90       178\n",
      "   macro avg       0.91      0.90      0.90       178\n",
      "weighted avg       0.91      0.90      0.90       178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "X = df_reduce_RFC_instances.drop(columns=['Class'])\n",
    "y = df_reduce_RFC_instances['Class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "print(\"Dimensiones de los conjuntos:\")\n",
    "print(f\"Conjunto de entrenamiento: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Conjunto de prueba: {X_test.shape}, {y_test.shape}\")\n",
    "\n",
    "base_estimator = GaussianNB()\n",
    "bagging = BaggingClassifier(estimator=base_estimator, random_state=0)\n",
    "\n",
    "# Configura el GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=bagging, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Ajusta el modelo a los datos de entrenamiento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Imprime los mejores parámetros y su desempeño\n",
    "print(\"Mejores parámetros:\", grid_search.best_params_)\n",
    "print(\"Mejor puntuación de validación cruzada:\", grid_search.best_score_)\n",
    "\n",
    "# Evalúa el mejor modelo en los datos de prueba\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(\"Informe completo en datos de prueba\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMPROBAMOS EL RESULTADO CON EL CONJUNTO DE TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión:\n",
      "[[28390    42]\n",
      " [    8    41]]\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Correctas       1.00      1.00      1.00     28432\n",
      "Fraudulentas       0.49      0.84      0.62        49\n",
      "\n",
      "    accuracy                           1.00     28481\n",
      "   macro avg       0.75      0.92      0.81     28481\n",
      "weighted avg       1.00      1.00      1.00     28481\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Configura el modelo con los mejores parámetros\n",
    "bagging_best = BaggingClassifier(\n",
    "    estimator=GaussianNB(),  \n",
    "    n_estimators=10,                     \n",
    "    max_samples=0.7,                     \n",
    "    max_features=1.0,                   \n",
    "    bootstrap=False,\n",
    "    bootstrap_features=True,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "X = df_reduce_RFC_instances.drop(columns=['Class'])\n",
    "y = df_reduce_RFC_instances['Class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Entrena el modelo con los datos de entrenamiento\n",
    "bagging_best.fit(X_train, y_train)\n",
    "\n",
    "# Evalúa el modelo en los datos de prueba\n",
    "y_pred_rfc = bagging_best.predict(X_reduce_RFC)\n",
    "\n",
    "# Calcular la matriz de confusión\n",
    "conf_matrix = confusion_matrix(y_test_final, y_pred_rfc)\n",
    "report = classification_report(y_test_final, y_pred_rfc, target_names=['Correctas', 'Fraudulentas'])\n",
    "# Mostrar la matriz de confusión\n",
    "print(\"Matriz de confusión:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"Reporte de Clasificación:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones de los conjuntos:\n",
      "Conjunto de entrenamiento: (708, 10), (708,)\n",
      "Conjunto de prueba: (178, 10), (178,)\n",
      "Mejores parámetros: {'bootstrap': False, 'bootstrap_features': True, 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 10}\n",
      "Mejor puntuación de validación cruzada: 0.9265707721506343\n",
      "Informe completo en datos de prueba\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92        89\n",
      "           1       0.96      0.87      0.91        89\n",
      "\n",
      "    accuracy                           0.92       178\n",
      "   macro avg       0.92      0.92      0.92       178\n",
      "weighted avg       0.92      0.92      0.92       178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "X = df_reduce_RFC_instances.drop(columns=['Class'])\n",
    "y = df_reduce_RFC_instances['Class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "print(\"Dimensiones de los conjuntos:\")\n",
    "print(f\"Conjunto de entrenamiento: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Conjunto de prueba: {X_test.shape}, {y_test.shape}\")\n",
    "\n",
    "base_estimator = RandomForestClassifier()\n",
    "bagging = BaggingClassifier(estimator=base_estimator, random_state=0)\n",
    "\n",
    "# Configura el GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=bagging, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Ajusta el modelo a los datos de entrenamiento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Imprime los mejores parámetros y su desempeño\n",
    "print(\"Mejores parámetros:\", grid_search.best_params_)\n",
    "print(\"Mejor puntuación de validación cruzada:\", grid_search.best_score_)\n",
    "\n",
    "# Evalúa el mejor modelo en los datos de prueba\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(\"Informe completo en datos de prueba\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMPROBAMOS EL RESULTADO CON EL CONJUNTO DE TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Configura el modelo con los mejores parámetros\n",
    "bagging_best = BaggingClassifier(\n",
    "    estimator=RandomForestClassifier(),  \n",
    "    n_estimators=10,                     \n",
    "    max_samples=0.7,                     \n",
    "    max_features=1.0,                   \n",
    "    bootstrap=False,\n",
    "    bootstrap_features=True,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "X = df_reduce_RFC_instances.drop(columns=['Class'])\n",
    "y = df_reduce_RFC_instances['Class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Entrena el modelo con los datos de entrenamiento\n",
    "bagging_best.fit(X_train, y_train)\n",
    "\n",
    "# Evalúa el modelo en los datos de prueba\n",
    "y_pred_rfc = bagging_best.predict(X_reduce_RFC)\n",
    "\n",
    "# Calcular la matriz de confusión\n",
    "conf_matrix = confusion_matrix(y_test_final, y_pred_rfc)\n",
    "report = classification_report(y_test_final, y_pred_rfc, target_names=['Correctas', 'Fraudulentas'])\n",
    "# Mostrar la matriz de confusión\n",
    "print(\"Matriz de confusión:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"Reporte de Clasificación:\")\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
