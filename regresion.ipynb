{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score, mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    \"reduce_mrmr_instances\": pd.read_csv('./data/df_reduce_mrmr_instances.csv'),\n",
    "    \"reduce_mrmr_instances_hard\": pd.read_csv('./data/df_reduce_mrmr_instances_hard.csv'),\n",
    "    \"reduce_RFC_instances\": pd.read_csv('./data/df_reduce_RFC_instances.csv'),\n",
    "    \"reduce_RFC_instances_hard\": pd.read_csv('./data/df_reduce_RFC_instances_hard.csv'),\n",
    "    \"reduce_mrmr_instances_GLVQ\": pd.read_csv('./data/df_reduce_mrmr_instances_GLVQ.csv'),\n",
    "    \"reduce_RFC_instances_GLVQ\": pd.read_csv('./data/df_reduce_RFC_instances_GLVQ.csv'),\n",
    "    # \"train_data\": pd.read_csv('./data/train_data.csv')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regresion con mrMr clusterCentroid_soft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n",
      "Mejores parámetros: {'C': 0.1, 'class_weight': 'balanced', 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "Mejor puntuación de validación cruzada: 0.8545499950054939\n"
     ]
    }
   ],
   "source": [
    "df_reduce_mrmr_instances = datasets[\"reduce_mrmr_instances\"]\n",
    "X = df_reduce_mrmr_instances.drop(columns=['Class'])\n",
    "y = df_reduce_mrmr_instances['Class']\n",
    "\n",
    "# Dividir en conjunto de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "param_grid = [\n",
    "    # Configuración para 'elasticnet'\n",
    "    {\n",
    "        'penalty': ['elasticnet'],\n",
    "        'solver': ['saga'],  # Solo 'saga' es compatible con elasticnet\n",
    "        'C': [0.1, 1, 10],\n",
    "        'l1_ratio': [0.5],\n",
    "        'tol': [0.0001, 0.001],\n",
    "        'max_iter': [100, 200],\n",
    "        'class_weight': [None, 'balanced'],\n",
    "        'fit_intercept': [True],\n",
    "    },\n",
    "    # Configuración para 'l1' y 'l2'\n",
    "    {\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'solver': ['liblinear', 'saga'],  # Solvers compatibles con l1 y l2\n",
    "        'C': [0.1, 1, 10],\n",
    "        'tol': [0.0001, 0.001],\n",
    "        'max_iter': [100, 200],\n",
    "        'class_weight': [None, 'balanced'],\n",
    "        'fit_intercept': [True],\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "# Configurar el modelo de regresión logística\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "# Usar GridSearchCV para buscar la mejor combinación de parámetros\n",
    "grid_search = GridSearchCV(estimator=log_reg, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "\n",
    "# Ajustar el modelo a los datos de entrenamiento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Obtener los mejores parámetros y el mejor puntaje\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Mejores parámetros:\", best_params)\n",
    "print(\"Mejor puntuación de validación cruzada:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión en el conjunto de prueba: 0.8539325842696629\n",
      "RMSE: 0.3821876708246056\n",
      "MAE: 0.14606741573033707\n",
      "\n",
      "Matriz de Confusión:\n",
      "[[92  2]\n",
      " [24 60]]\n",
      "\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Correctas       0.79      0.98      0.88        94\n",
      "Fraudulentas       0.97      0.71      0.82        84\n",
      "\n",
      "    accuracy                           0.85       178\n",
      "   macro avg       0.88      0.85      0.85       178\n",
      "weighted avg       0.88      0.85      0.85       178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo en el conjunto de prueba\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Precisión en el conjunto de prueba:\", test_accuracy)\n",
    "\n",
    "# Calcular la matriz de confusión y el reporte de clasificación\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred, target_names=['Correctas', 'Fraudulentas'])\n",
    "\n",
    "# Calcular el error cuadrático medio\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f'RMSE: {rmse}')\n",
    "\n",
    "# Calcular el error absoluto medio\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'MAE: {mae}')\n",
    "\n",
    "# Mostrar la matriz de confusión y el reporte\n",
    "print(\"\\nMatriz de Confusión:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"\\nReporte de Clasificación:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regresion con mrMr clusterCentroid_hard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n",
      "Mejores parámetros: {'C': 0.1, 'class_weight': 'balanced', 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "Mejor puntuación de validación cruzada: 0.8545499950054939\n"
     ]
    }
   ],
   "source": [
    "df_reduce_mrmr_instances_hard = datasets[\"reduce_mrmr_instances_hard\"]\n",
    "X = df_reduce_mrmr_instances_hard.drop(columns=['Class'])\n",
    "y = df_reduce_mrmr_instances_hard['Class']\n",
    "\n",
    "# Dividir en conjunto de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "param_grid = [\n",
    "    # Configuración para 'elasticnet'\n",
    "    {\n",
    "        'penalty': ['elasticnet'],\n",
    "        'solver': ['saga'],  # Solo 'saga' es compatible con elasticnet\n",
    "        'C': [0.1, 1, 10],\n",
    "        'l1_ratio': [0.5],\n",
    "        'tol': [0.0001, 0.001],\n",
    "        'max_iter': [100, 200],\n",
    "        'class_weight': [None, 'balanced'],\n",
    "        'fit_intercept': [True],\n",
    "    },\n",
    "    # Configuración para 'l1' y 'l2'\n",
    "    {\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'solver': ['liblinear', 'saga'],  # Solvers compatibles con l1 y l2\n",
    "        'C': [0.1, 1, 10],\n",
    "        'tol': [0.0001, 0.001],\n",
    "        'max_iter': [100, 200],\n",
    "        'class_weight': [None, 'balanced'],\n",
    "        'fit_intercept': [True],\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "# Configurar el modelo de regresión logística\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "# Usar GridSearchCV para buscar la mejor combinación de parámetros\n",
    "grid_search = GridSearchCV(estimator=log_reg, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "\n",
    "# Ajustar el modelo a los datos de entrenamiento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Obtener los mejores parámetros y el mejor puntaje\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Mejores parámetros:\", best_params)\n",
    "print(\"Mejor puntuación de validación cruzada:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión en el conjunto de prueba: 0.848314606741573\n",
      "RMSE: 0.3894680901671239\n",
      "MAE: 0.15168539325842698\n",
      "\n",
      "Matriz de Confusión:\n",
      "[[91  3]\n",
      " [24 60]]\n",
      "\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Correctas       0.79      0.97      0.87        94\n",
      "Fraudulentas       0.95      0.71      0.82        84\n",
      "\n",
      "    accuracy                           0.85       178\n",
      "   macro avg       0.87      0.84      0.84       178\n",
      "weighted avg       0.87      0.85      0.85       178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo en el conjunto de prueba\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Precisión en el conjunto de prueba:\", test_accuracy)\n",
    "\n",
    "# Calcular la matriz de confusión y el reporte de clasificación\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred, target_names=['Correctas', 'Fraudulentas'])\n",
    "\n",
    "# Calcular el error cuadrático medio\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f'RMSE: {rmse}')\n",
    "\n",
    "# Calcular el error absoluto medio\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'MAE: {mae}')\n",
    "\n",
    "# Mostrar la matriz de confusión y el reporte\n",
    "print(\"\\nMatriz de Confusión:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"\\nReporte de Clasificación:\")\n",
    "print(report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regresion con mrMr y GLVQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No se van a usar los acercamientos con GLVQ dada la imposibilidad con el entrenamiento del modelo de regresion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regresion con RFC clusterCentroid_soft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n",
      "Mejores parámetros: {'C': 1, 'class_weight': None, 'fit_intercept': True, 'l1_ratio': 0.5, 'max_iter': 200, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001}\n",
      "Mejor puntuación de validación cruzada: 0.925162321446409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joses\\miniconda3\\envs\\pre_procesamiento\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df_reduce_RFC_instances = datasets[\"reduce_RFC_instances\"]\n",
    "X = df_reduce_RFC_instances.drop(columns=['Class'])\n",
    "y = df_reduce_RFC_instances['Class']\n",
    "\n",
    "# Dividir en conjunto de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "param_grid = [\n",
    "    # Configuración para 'elasticnet'\n",
    "    {\n",
    "        'penalty': ['elasticnet'],\n",
    "        'solver': ['saga'],  # Solo 'saga' es compatible con elasticnet\n",
    "        'C': [0.1, 1, 10],\n",
    "        'l1_ratio': [0.5],\n",
    "        'tol': [0.0001, 0.001],\n",
    "        'max_iter': [100, 200],\n",
    "        'class_weight': [None, 'balanced'],\n",
    "        'fit_intercept': [True],\n",
    "    },\n",
    "    # Configuración para 'l1' y 'l2'\n",
    "    {\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'solver': ['liblinear', 'saga'],  # Solvers compatibles con l1 y l2\n",
    "        'C': [0.1, 1, 10],\n",
    "        'tol': [0.0001, 0.001],\n",
    "        'max_iter': [100, 200],\n",
    "        'class_weight': [None, 'balanced'],\n",
    "        'fit_intercept': [True],\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "# Configurar el modelo de regresión logística\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "# Usar GridSearchCV para buscar la mejor combinación de parámetros\n",
    "grid_search = GridSearchCV(estimator=log_reg, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "\n",
    "# Ajustar el modelo a los datos de entrenamiento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Obtener los mejores parámetros y el mejor puntaje\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Mejores parámetros:\", best_params)\n",
    "print(\"Mejor puntuación de validación cruzada:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión en el conjunto de prueba: 0.9157303370786517\n",
      "RMSE: 0.29029237489356885\n",
      "MAE: 0.08426966292134831\n",
      "\n",
      "Matriz de Confusión:\n",
      "[[89  5]\n",
      " [10 74]]\n",
      "\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Correctas       0.90      0.95      0.92        94\n",
      "Fraudulentas       0.94      0.88      0.91        84\n",
      "\n",
      "    accuracy                           0.92       178\n",
      "   macro avg       0.92      0.91      0.92       178\n",
      "weighted avg       0.92      0.92      0.92       178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo en el conjunto de prueba\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Precisión en el conjunto de prueba:\", test_accuracy)\n",
    "\n",
    "# Calcular el error cuadrático medio\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f'RMSE: {rmse}')\n",
    "\n",
    "# Calcular el error absoluto medio\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'MAE: {mae}')\n",
    "\n",
    "# Calcular la matriz de confusión y el reporte de clasificación\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred, target_names=['Correctas', 'Fraudulentas'])\n",
    "\n",
    "# Mostrar la matriz de confusión y el reporte\n",
    "print(\"\\nMatriz de Confusión:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"\\nReporte de Clasificación:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regresion con RFC clusterCentroid_hard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n",
      "Mejores parámetros: {'C': 10, 'class_weight': 'balanced', 'fit_intercept': True, 'l1_ratio': 0.5, 'max_iter': 200, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001}\n",
      "Mejor puntuación de validación cruzada: 0.925162321446409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joses\\miniconda3\\envs\\pre_procesamiento\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df_reduce_RFC_instances_hard = datasets[\"reduce_RFC_instances_hard\"]\n",
    "X = df_reduce_RFC_instances_hard.drop(columns=['Class'])\n",
    "y = df_reduce_RFC_instances_hard['Class']\n",
    "\n",
    "# Dividir en conjunto de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "param_grid = [\n",
    "    # Configuración para 'elasticnet'\n",
    "    {\n",
    "        'penalty': ['elasticnet'],\n",
    "        'solver': ['saga'],  # Solo 'saga' es compatible con elasticnet\n",
    "        'C': [0.1, 1, 10],\n",
    "        'l1_ratio': [0.5],\n",
    "        'tol': [0.0001, 0.001],\n",
    "        'max_iter': [100, 200],\n",
    "        'class_weight': [None, 'balanced'],\n",
    "        'fit_intercept': [True],\n",
    "    },\n",
    "    # Configuración para 'l1' y 'l2'\n",
    "    {\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'solver': ['liblinear', 'saga'],  # Solvers compatibles con l1 y l2\n",
    "        'C': [0.1, 1, 10],\n",
    "        'tol': [0.0001, 0.001],\n",
    "        'max_iter': [100, 200],\n",
    "        'class_weight': [None, 'balanced'],\n",
    "        'fit_intercept': [True],\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "# Configurar el modelo de regresión logística\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "# Usar GridSearchCV para buscar la mejor combinación de parámetros\n",
    "grid_search = GridSearchCV(estimator=log_reg, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "\n",
    "# Ajustar el modelo a los datos de entrenamiento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Obtener los mejores parámetros y el mejor puntaje\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Mejores parámetros:\", best_params)\n",
    "print(\"Mejor puntuación de validación cruzada:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión en el conjunto de prueba: 0.9157303370786517\n",
      "RMSE: 0.29029237489356885\n",
      "MAE: 0.08426966292134831\n",
      "\n",
      "Matriz de Confusión:\n",
      "[[89  5]\n",
      " [10 74]]\n",
      "\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Correctas       0.90      0.95      0.92        94\n",
      "Fraudulentas       0.94      0.88      0.91        84\n",
      "\n",
      "    accuracy                           0.92       178\n",
      "   macro avg       0.92      0.91      0.92       178\n",
      "weighted avg       0.92      0.92      0.92       178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo en el conjunto de prueba\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Precisión en el conjunto de prueba:\", test_accuracy)\n",
    "\n",
    "# Calcular la matriz de confusión y el reporte de clasificación\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred, target_names=['Correctas', 'Fraudulentas'])\n",
    "\n",
    "# Calcular el error cuadrático medio\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f'RMSE: {rmse}')\n",
    "\n",
    "# Calcular el error absoluto medio\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'MAE: {mae}')\n",
    "\n",
    "# Mostrar la matriz de confusión y el reporte\n",
    "print(\"\\nMatriz de Confusión:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"\\nReporte de Clasificación:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regresion con RFC y GLVQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No se va a usar el acercamiento con GLVQ dada la imposibilidad con el entrenamiento del modelo de regresion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train_data con modelo simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.04%\n",
      "F1-Score: 10.08%\n",
      "RMSE: 0.17196294892524483\n",
      "MAE: 0.02957125580306636\n",
      "\n",
      "Matriz de Confusión:\n",
      "[[49665  1512]\n",
      " [    4    85]]\n",
      "\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Correctas       1.00      0.97      0.98     51177\n",
      "Fraudulentas       0.05      0.96      0.10        89\n",
      "\n",
      "    accuracy                           0.97     51266\n",
      "   macro avg       0.53      0.96      0.54     51266\n",
      "weighted avg       1.00      0.97      0.98     51266\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "train_data = pd.read_csv('./data/train_data.csv')\n",
    "\n",
    "X = train_data.drop(columns=['Class'])\n",
    "y = train_data['Class']\n",
    "\n",
    "# Dividir los datos en entrenamiento y testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Aplicar SMOTE para equilibrar las clases en los datos de entrenamiento\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Estandarizar las características (mejora el desempeño de la regresión logística)\n",
    "scaler = StandardScaler()\n",
    "X_train_balanced = scaler.fit_transform(X_train_balanced)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Crear y entrenar el modelo de Regresión Logística\n",
    "model = LogisticRegression(solver='lbfgs', max_iter=1000, class_weight='balanced')\n",
    "model.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Predecir en los datos de testeo\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calcular las métricas\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Calcular F1-Score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f'F1-Score: {f1 * 100:.2f}%')\n",
    "\n",
    "# Calcular el error cuadrático medio\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f'RMSE: {rmse}')\n",
    "\n",
    "# Calcular el error absoluto medio\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'MAE: {mae}')\n",
    "\n",
    "# Calcular la matriz de confusión y el reporte de clasificación\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred, target_names=['Correctas', 'Fraudulentas'])\n",
    "\n",
    "# Mostrar la matriz de confusión y el reporte\n",
    "print(\"\\nMatriz de Confusión:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"\\nReporte de Clasificación:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusiones sobre los Modelos de Regresión y Clasificación\n",
    "\n",
    "Se evaluaron diversos modelos de clasificación en diferentes particiones de conjuntos de datos. A continuación, se resumen los resultados y observaciones clave:\n",
    "\n",
    "## Comparación de Modelos\n",
    "\n",
    "| Modelo                      | Precisión (Test) | RMSE   | MAE    | Recall Correctas | Recall Fraudulentas | F1 Correctas | F1 Fraudulentas |\n",
    "|-----------------------------|------------------|--------|--------|------------------|---------------------|--------------|-----------------|\n",
    "| **mrMr clusterCentroid_soft** | 85.39%           | 0.3822 | 0.1461 | 98%              | 71%                 | 0.88         | 0.82            |\n",
    "| **mrMr clusterCentroid_hard** | 84.83%           | 0.3895 | 0.1517 | 97%              | 71%                 | 0.87         | 0.82            |\n",
    "| **RFC clusterCentroid_soft** | 91.57%           | 0.2903 | 0.0843 | 95%              | 88%                 | 0.92         | 0.91            |\n",
    "| **RFC clusterCentroid_hard** | 91.57%           | 0.2903 | 0.0843 | 95%              | 88%                 | 0.92         | 0.91            |\n",
    "| **Regresión Logística**      | 97.04%           | 0.1720 | 0.0296 | 97%              | 96%                 | 0.98         | 0.10            |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observaciones Clave\n",
    "\n",
    "1. **RFC (Random Forest Classifier)**:\n",
    "   - Los modelos basados en RFC obtuvieron la mejor precisión general (91.57%) en las particiones con centroides suavizados y rígidos.\n",
    "   - Muestran un equilibrio sólido entre las clases, con valores altos de *recall* y *f1-score* para ambas categorías (Correctas y Fraudulentas).\n",
    "   - Reducción significativa de error (RMSE y MAE) en comparación con los modelos `mrMr`.\n",
    "\n",
    "2. **mrMr (Feature Selection)**:\n",
    "   - Los modelos `mrMr` tienen una precisión ligeramente menor (~85%), siendo algo menos consistentes en la detección de casos fraudulentos (*recall* de 71%).\n",
    "   - Aunque la matriz de confusión muestra resultados aceptables, los valores de error (RMSE y MAE) son más altos en comparación con RFC.\n",
    "\n",
    "3. **Regresión Logística (Modelo Base)**:\n",
    "   - A pesar de tener una alta precisión global (97.04%), el modelo de regresión logística sufre de un claro desbalance en la predicción de las clases.\n",
    "   - *F1-score* extremadamente bajo para casos fraudulentos (0.10), lo que refleja problemas serios para detectar correctamente estas instancias, a pesar de un *recall* alto (96%).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones Generales\n",
    "\n",
    "- **RFC** es el modelo más robusto y equilibrado para este conjunto de datos, tanto en precisión como en detección de instancias fraudulentas y no fraudulentas.\n",
    "- Los modelos `mrMr`, aunque menos precisos, ofrecen resultados aceptables y podrían ser útiles si la interpretabilidad de las características seleccionadas es prioritaria.\n",
    "- El modelo de regresión logística, a pesar de su alta precisión, tiene una gran desventaja en la clasificación de casos minoritarios (fraudulentos), lo que limita su aplicabilidad en escenarios donde estos son críticos.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pre_procesamiento",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
