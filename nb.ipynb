{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación Naive-Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En cuanto al modelo de Naive-Bayes a usar, se ha elegido GaussianNB porque es la mejor opción para datos continuos que se distribuyen de forma normal, además de que es bastante robusto y suele ofrecer buenos resultados incluso en casos no ideales. Se impone a otros modelos como es el caso de:\n",
    "- MultinomialNB ya que está diseñado para datos discretos\n",
    "- BernoulliNB porque es específico para datos binarios (0 o 1), como presencia/ausencia de características.\n",
    "- CategoricalNB ya que es específico para variables categóricas puras \n",
    "- ComplementNB por el mismo motivo que MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold, cross_val_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos cargados exitosamente:\n",
      "train_data: (256326, 31)\n",
      "Class\n",
      "0    255883\n",
      "1       443\n",
      "Name: count, dtype: int64\n",
      "test_data: (28481, 31)\n",
      "Class\n",
      "0    28432\n",
      "1       49\n",
      "Name: count, dtype: int64\n",
      "df_reduce_mrmr: (256326, 11)\n",
      "Class\n",
      "0    255883\n",
      "1       443\n",
      "Name: count, dtype: int64\n",
      "df_reduce_mrmr_instances: (886, 11)\n",
      "Class\n",
      "0    443\n",
      "1    443\n",
      "Name: count, dtype: int64\n",
      "df_reduce_mrmr_instances hard: (886, 11)\n",
      "Class\n",
      "0    443\n",
      "1    443\n",
      "Name: count, dtype: int64\n",
      "df_reduce_mrmr_instances_GLVQ: (2, 11)\n",
      "Class\n",
      "0    1\n",
      "1    1\n",
      "Name: count, dtype: int64\n",
      "df_X_train_reduce_RFC: (256326, 11)\n",
      "Class\n",
      "0    255883\n",
      "1       443\n",
      "Name: count, dtype: int64\n",
      "df_reduce_RFC_instances: (886, 11)\n",
      "Class\n",
      "0    443\n",
      "1    443\n",
      "Name: count, dtype: int64\n",
      "df_reduce_RFC_instances hard: (886, 11)\n",
      "Class\n",
      "0    443\n",
      "1    443\n",
      "Name: count, dtype: int64\n",
      "df_reduce_RFC_instances_GLVQ: (2, 11)\n",
      "Class\n",
      "0    1\n",
      "1    1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data_path = './data/'\n",
    "\n",
    "train_data = pd.read_csv(f'{data_path}train_data.csv')\n",
    "test_data = pd.read_csv(f'{data_path}test_data.csv')\n",
    "\n",
    "df_reduce_mrmr = pd.read_csv(f'{data_path}X_train_reduce_mrmr.csv')\n",
    "df_reduce_mrmr_instances = pd.read_csv(f'{data_path}df_reduce_mrmr_instances.csv')\n",
    "df_reduce_mrmr_instances_hard = pd.read_csv(f'{data_path}df_reduce_mrmr_instances_hard.csv')\n",
    "df_reduce_mrmr_instances_GLVQ = pd.read_csv(f'{data_path}df_reduce_mrmr_instances_GLVQ.csv')\n",
    "\n",
    "df_X_train_reduce_RFC = pd.read_csv(f'{data_path}df_X_train_reduce_RFC.csv')\n",
    "df_reduce_RFC_instances = pd.read_csv(f'{data_path}df_reduce_RFC_instances.csv')\n",
    "df_reduce_RFC_instances_hard = pd.read_csv(f'{data_path}df_reduce_RFC_instances_hard.csv')\n",
    "df_reduce_RFC_instances_GLVQ = pd.read_csv(f'{data_path}df_reduce_RFC_instances_GLVQ.csv')\n",
    "\n",
    "print(\"Datos cargados exitosamente:\")\n",
    "print(f\"train_data: {train_data.shape}\")\n",
    "print(train_data[\"Class\"].value_counts())\n",
    "print(f\"test_data: {test_data.shape}\")\n",
    "print(test_data[\"Class\"].value_counts())\n",
    "print(f\"df_reduce_mrmr: {df_reduce_mrmr.shape}\")\n",
    "print(df_reduce_mrmr[\"Class\"].value_counts())\n",
    "print(f\"df_reduce_mrmr_instances: {df_reduce_mrmr_instances.shape}\")\n",
    "print(df_reduce_mrmr_instances[\"Class\"].value_counts())\n",
    "print(f\"df_reduce_mrmr_instances hard: {df_reduce_mrmr_instances_hard.shape}\")\n",
    "print(df_reduce_mrmr_instances_hard[\"Class\"].value_counts())\n",
    "print(f\"df_reduce_mrmr_instances_GLVQ: {df_reduce_mrmr_instances_GLVQ.shape}\")\n",
    "print(df_reduce_mrmr_instances_GLVQ[\"Class\"].value_counts())\n",
    "print(f\"df_X_train_reduce_RFC: {df_X_train_reduce_RFC.shape}\")\n",
    "print(df_X_train_reduce_RFC[\"Class\"].value_counts())\n",
    "print(f\"df_reduce_RFC_instances: {df_reduce_RFC_instances.shape}\")\n",
    "print(df_reduce_RFC_instances[\"Class\"].value_counts())\n",
    "print(f\"df_reduce_RFC_instances hard: {df_reduce_RFC_instances_hard.shape}\")\n",
    "print(df_reduce_RFC_instances_hard[\"Class\"].value_counts())\n",
    "print(f\"df_reduce_RFC_instances_GLVQ: {df_reduce_RFC_instances_GLVQ.shape}\")\n",
    "print(df_reduce_RFC_instances_GLVQ[\"Class\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función para entrenar y evaluar Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_naive_bayes_with_cv(X, y, test_data, columns_to_keep):\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    model = GaussianNB()\n",
    "    y_pred_cv = cross_val_predict(model, X, y, cv=kfold)\n",
    "\n",
    "    conf_matrix = confusion_matrix(y, y_pred_cv)\n",
    "    report = classification_report(y, y_pred_cv, target_names=['Correctas', 'Fraudulentas'])\n",
    "\n",
    "    print(\"Resultados de validación cruzada:\")\n",
    "    print(\"Matriz de confusión entrenamiento:\")\n",
    "    print(conf_matrix)\n",
    "    print(\"\\nReporte de Clasificación entrenamiento:\")\n",
    "    print(report)\n",
    "\n",
    "    X_test_final = test_data[columns_to_keep]\n",
    "    y_test_final = test_data['Class']\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    for col in ['Amount', 'Time']:\n",
    "        if col in X_test_final.columns:\n",
    "            X_test_final[col] = scaler.fit_transform(X_test_final[[col]])\n",
    "\n",
    "    print(y_test_final.value_counts())\n",
    "\n",
    "    model.fit(X, y)  \n",
    "    y_pred_test = model.predict(X_test_final)\n",
    "\n",
    "    conf_matrix_test = confusion_matrix(y_test_final, y_pred_test)\n",
    "    report_test = classification_report(y_test_final, y_pred_test, target_names=['Correctas', 'Fraudulentas'])\n",
    "\n",
    "    print(\"\\nResultados en el conjunto de test:\")\n",
    "    print(\"Matriz de confusión del conjunto de test:\")\n",
    "    print(conf_matrix_test)\n",
    "    print(\"\\nReporte de Clasificación del conjunto de test:\")\n",
    "    print(report_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo con train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluación con train data ---\n",
      "Resultados de validación cruzada:\n",
      "Matriz de confusión entrenamiento:\n",
      "[[250284   5599]\n",
      " [    76    367]]\n",
      "\n",
      "Reporte de Clasificación entrenamiento:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Correctas       1.00      0.98      0.99    255883\n",
      "Fraudulentas       0.06      0.83      0.11       443\n",
      "\n",
      "    accuracy                           0.98    256326\n",
      "   macro avg       0.53      0.90      0.55    256326\n",
      "weighted avg       1.00      0.98      0.99    256326\n",
      "\n",
      "Class\n",
      "0    28432\n",
      "1       49\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_13428\\3805750772.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test_final[col] = scaler.fit_transform(X_test_final[[col]])\n",
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_13428\\3805750772.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test_final[col] = scaler.fit_transform(X_test_final[[col]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados en el conjunto de test:\n",
      "Matriz de confusión del conjunto de test:\n",
      "[[27718   714]\n",
      " [    8    41]]\n",
      "\n",
      "Reporte de Clasificación del conjunto de test:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Correctas       1.00      0.97      0.99     28432\n",
      "Fraudulentas       0.05      0.84      0.10        49\n",
      "\n",
      "    accuracy                           0.97     28481\n",
      "   macro avg       0.53      0.91      0.54     28481\n",
      "weighted avg       1.00      0.97      0.99     28481\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = train_data.drop(columns=['Class'])\n",
    "y = train_data['Class']\n",
    "columns = [\"Time\",\"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\",\"V7\",\"V8\",\"V9\",\"V10\",\"V11\",\"V12\",\"V13\",\"V14\",\"V15\",\"V16\",\"V17\",\"V18\",\"V19\",\"V20\",\"V21\",\"V22\",\"V23\",\"V24\",\"V25\",\"V26\",\"V27\",\"V28\",\"Amount\"]\n",
    "\n",
    "print(\"\\n--- Evaluación con train data ---\")\n",
    "train_and_evaluate_naive_bayes_with_cv(X, y, test_data, columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con los datos de entrenamiento podemos observar como en la clase fraudulentas obtenemos una precision (0.05) y f1-score (0.10) muy bajas, debido a que GaussianNB es muy sensible al desbalanceo de las clases y favorece a la clase mayoritaria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo con mRMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluación con mRMR ---\n",
      "Resultados de validación cruzada:\n",
      "Matriz de confusión entrenamiento:\n",
      "[[251736   4147]\n",
      " [   136    307]]\n",
      "\n",
      "Reporte de Clasificación entrenamiento:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Correctas       1.00      0.98      0.99    255883\n",
      "Fraudulentas       0.07      0.69      0.13       443\n",
      "\n",
      "    accuracy                           0.98    256326\n",
      "   macro avg       0.53      0.84      0.56    256326\n",
      "weighted avg       1.00      0.98      0.99    256326\n",
      "\n",
      "Class\n",
      "0    28432\n",
      "1       49\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_13428\\3805750772.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test_final[col] = scaler.fit_transform(X_test_final[[col]])\n",
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_13428\\3805750772.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test_final[col] = scaler.fit_transform(X_test_final[[col]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados en el conjunto de test:\n",
      "Matriz de confusión del conjunto de test:\n",
      "[[27846   586]\n",
      " [   11    38]]\n",
      "\n",
      "Reporte de Clasificación del conjunto de test:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Correctas       1.00      0.98      0.99     28432\n",
      "Fraudulentas       0.06      0.78      0.11        49\n",
      "\n",
      "    accuracy                           0.98     28481\n",
      "   macro avg       0.53      0.88      0.55     28481\n",
      "weighted avg       1.00      0.98      0.99     28481\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df_reduce_mrmr.drop(columns=['Class'])\n",
    "y = df_reduce_mrmr['Class']\n",
    "columns_to_keep_mrmr = ['V17', 'Time', 'Amount', 'V25', 'V20', 'V7', 'V13', 'V22', 'V19', 'V23']\n",
    "\n",
    "print(\"\\n--- Evaluación con mRMR ---\")\n",
    "train_and_evaluate_naive_bayes_with_cv(X, y, test_data, columns_to_keep_mrmr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que reduciendo las características con mRMR, aumentan muy ligeramente la precision, a 0.06 y el f1-score, a 0.11. La causa de unas métricas tan bajas, probablemente sea el desbalanceo de clases, tal y como se comentaba en el caso de los datos de entrenamiento. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo con RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluación con RFC ---\n",
      "Resultados de validación cruzada:\n",
      "Matriz de confusión entrenamiento:\n",
      "[[253712   2171]\n",
      " [    67    376]]\n",
      "\n",
      "Reporte de Clasificación entrenamiento:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Correctas       1.00      0.99      1.00    255883\n",
      "Fraudulentas       0.15      0.85      0.25       443\n",
      "\n",
      "    accuracy                           0.99    256326\n",
      "   macro avg       0.57      0.92      0.62    256326\n",
      "weighted avg       1.00      0.99      0.99    256326\n",
      "\n",
      "Class\n",
      "0    28432\n",
      "1       49\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Resultados en el conjunto de test:\n",
      "Matriz de confusión del conjunto de test:\n",
      "[[28151   281]\n",
      " [    6    43]]\n",
      "\n",
      "Reporte de Clasificación del conjunto de test:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Correctas       1.00      0.99      0.99     28432\n",
      "Fraudulentas       0.13      0.88      0.23        49\n",
      "\n",
      "    accuracy                           0.99     28481\n",
      "   macro avg       0.57      0.93      0.61     28481\n",
      "weighted avg       1.00      0.99      0.99     28481\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df_X_train_reduce_RFC.drop(columns=['Class'])\n",
    "y = df_X_train_reduce_RFC['Class']\n",
    "columns_to_keep_RFC = ['V17', 'V16', 'V12', 'V14', 'V11', 'V10', 'V9', 'V4', 'V18', 'V7']\n",
    "\n",
    "print(\"\\n--- Evaluación con RFC ---\")\n",
    "train_and_evaluate_naive_bayes_with_cv(X, y, test_data, columns_to_keep_RFC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al reducir las características usando RFC, vemos un aumento más considerable tanto en la precision (0.13) como en el f1-score (0.23) debido a que RFC hace un mejor manejo de los datos desbalanceados por su enfoque no lineal, que le permite capturar relaciones complejas, y por ser un conjunto de árboles, por lo que maneja mejor la variabilidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo con mRMR (ClusterCentroids_soft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluación con mRMR ClusterCentroids_soft ---\n",
      "Resultados de validación cruzada:\n",
      "Matriz de confusión entrenamiento:\n",
      "[[102 341]\n",
      " [ 15 428]]\n",
      "\n",
      "Reporte de Clasificación entrenamiento:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Correctas       0.87      0.23      0.36       443\n",
      "Fraudulentas       0.56      0.97      0.71       443\n",
      "\n",
      "    accuracy                           0.60       886\n",
      "   macro avg       0.71      0.60      0.54       886\n",
      "weighted avg       0.71      0.60      0.54       886\n",
      "\n",
      "Class\n",
      "0    28432\n",
      "1       49\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Resultados en el conjunto de test:\n",
      "Matriz de confusión del conjunto de test:\n",
      "[[ 1838 26594]\n",
      " [    1    48]]\n",
      "\n",
      "Reporte de Clasificación del conjunto de test:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Correctas       1.00      0.06      0.12     28432\n",
      "Fraudulentas       0.00      0.98      0.00        49\n",
      "\n",
      "    accuracy                           0.07     28481\n",
      "   macro avg       0.50      0.52      0.06     28481\n",
      "weighted avg       1.00      0.07      0.12     28481\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_13428\\3805750772.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test_final[col] = scaler.fit_transform(X_test_final[[col]])\n",
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_13428\\3805750772.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test_final[col] = scaler.fit_transform(X_test_final[[col]])\n"
     ]
    }
   ],
   "source": [
    "X = df_reduce_mrmr_instances.drop(columns=['Class'])\n",
    "y = df_reduce_mrmr_instances['Class']\n",
    "columns_to_keep_mrmr = ['V17', 'Time', 'Amount', 'V25', 'V20', 'V7', 'V13', 'V22', 'V19', 'V23']\n",
    "\n",
    "print(\"\\n--- Evaluación con mRMR ClusterCentroids_soft ---\")\n",
    "train_and_evaluate_naive_bayes_with_cv(X, y, test_data, columns_to_keep_mrmr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al reducir el número de instancias con mRMR, se ha reducido la precision y el f1-score para la clase minoritaria, hasta 0.00 en ambos casos. Sin embargo, en el conjunto de entrenamiento se lograba una precisión de 0.56 y un f1-score de 0.71. Esto probablemente se dé porque al balancear las clases se ha introducido ruido que favorece a la clase fraudulentas, lo que empeora el rendimiento del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo con RFC (ClusterCentroids_soft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluación con RFC ClusterCentroids_soft ---\n",
      "Resultados de validación cruzada:\n",
      "Matriz de confusión entrenamiento:\n",
      "[[428  15]\n",
      " [ 82 361]]\n",
      "\n",
      "Reporte de Clasificación entrenamiento:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Correctas       0.84      0.97      0.90       443\n",
      "Fraudulentas       0.96      0.81      0.88       443\n",
      "\n",
      "    accuracy                           0.89       886\n",
      "   macro avg       0.90      0.89      0.89       886\n",
      "weighted avg       0.90      0.89      0.89       886\n",
      "\n",
      "Class\n",
      "0    28432\n",
      "1       49\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Resultados en el conjunto de test:\n",
      "Matriz de confusión del conjunto de test:\n",
      "[[28390    42]\n",
      " [    8    41]]\n",
      "\n",
      "Reporte de Clasificación del conjunto de test:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Correctas       1.00      1.00      1.00     28432\n",
      "Fraudulentas       0.49      0.84      0.62        49\n",
      "\n",
      "    accuracy                           1.00     28481\n",
      "   macro avg       0.75      0.92      0.81     28481\n",
      "weighted avg       1.00      1.00      1.00     28481\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df_reduce_RFC_instances.drop(columns=['Class'])\n",
    "y = df_reduce_RFC_instances['Class']\n",
    "columns_to_keep_RFC = ['V17', 'V16', 'V12', 'V14', 'V11', 'V10', 'V9', 'V4', 'V18', 'V7']\n",
    "\n",
    "print(\"\\n--- Evaluación con RFC ClusterCentroids_soft ---\")\n",
    "train_and_evaluate_naive_bayes_with_cv(X, y, test_data, columns_to_keep_RFC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, el balanceo de las clases y la reducción de instancias sí ha hecho que el rendimiento del modelo mejore bastante, logrando una precision de 0.49 y un f1-score de 0.62 para la clase fraudulentas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo con mRMR (ClusterCentroids_hard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluación con mRMR ClusterCentroids_hard ---\n",
      "Resultados de validación cruzada:\n",
      "Matriz de confusión entrenamiento:\n",
      "[[ 98 345]\n",
      " [ 17 426]]\n",
      "\n",
      "Reporte de Clasificación entrenamiento:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Correctas       0.85      0.22      0.35       443\n",
      "Fraudulentas       0.55      0.96      0.70       443\n",
      "\n",
      "    accuracy                           0.59       886\n",
      "   macro avg       0.70      0.59      0.53       886\n",
      "weighted avg       0.70      0.59      0.53       886\n",
      "\n",
      "Class\n",
      "0    28432\n",
      "1       49\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Resultados en el conjunto de test:\n",
      "Matriz de confusión del conjunto de test:\n",
      "[[ 1954 26478]\n",
      " [    1    48]]\n",
      "\n",
      "Reporte de Clasificación del conjunto de test:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Correctas       1.00      0.07      0.13     28432\n",
      "Fraudulentas       0.00      0.98      0.00        49\n",
      "\n",
      "    accuracy                           0.07     28481\n",
      "   macro avg       0.50      0.52      0.07     28481\n",
      "weighted avg       1.00      0.07      0.13     28481\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_13428\\3805750772.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test_final[col] = scaler.fit_transform(X_test_final[[col]])\n",
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_13428\\3805750772.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test_final[col] = scaler.fit_transform(X_test_final[[col]])\n"
     ]
    }
   ],
   "source": [
    "X = df_reduce_mrmr_instances_hard.drop(columns=['Class'])\n",
    "y = df_reduce_mrmr_instances_hard['Class']\n",
    "columns_to_keep_mrmr = ['V17', 'Time', 'Amount', 'V25', 'V20', 'V7', 'V13', 'V22', 'V19', 'V23']\n",
    "\n",
    "print(\"\\n--- Evaluación con mRMR ClusterCentroids_hard ---\")\n",
    "train_and_evaluate_naive_bayes_with_cv(X, y, test_data, columns_to_keep_mrmr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados son idénticos a los obtenidos con ClusterCentroids_soft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo con RFC (ClusterCentroids_hard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluación con RFC ClusterCentroids_hard ---\n",
      "Resultados de validación cruzada:\n",
      "Matriz de confusión entrenamiento:\n",
      "[[428  15]\n",
      " [ 82 361]]\n",
      "\n",
      "Reporte de Clasificación entrenamiento:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Correctas       0.84      0.97      0.90       443\n",
      "Fraudulentas       0.96      0.81      0.88       443\n",
      "\n",
      "    accuracy                           0.89       886\n",
      "   macro avg       0.90      0.89      0.89       886\n",
      "weighted avg       0.90      0.89      0.89       886\n",
      "\n",
      "Class\n",
      "0    28432\n",
      "1       49\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Resultados en el conjunto de test:\n",
      "Matriz de confusión del conjunto de test:\n",
      "[[28391    41]\n",
      " [    8    41]]\n",
      "\n",
      "Reporte de Clasificación del conjunto de test:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Correctas       1.00      1.00      1.00     28432\n",
      "Fraudulentas       0.50      0.84      0.63        49\n",
      "\n",
      "    accuracy                           1.00     28481\n",
      "   macro avg       0.75      0.92      0.81     28481\n",
      "weighted avg       1.00      1.00      1.00     28481\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df_reduce_RFC_instances_hard.drop(columns=['Class'])\n",
    "y = df_reduce_RFC_instances_hard['Class']\n",
    "columns_to_keep_RFC = ['V17', 'V16', 'V12', 'V14', 'V11', 'V10', 'V9', 'V4', 'V18', 'V7']\n",
    "\n",
    "print(\"\\n--- Evaluación con RFC ClusterCentroids_hard ---\")\n",
    "train_and_evaluate_naive_bayes_with_cv(X, y, test_data, columns_to_keep_RFC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados son ligeramente mejores a los obtenidos con ClusterCentroids_soft con una precisión de 0.50 y un f1-score de 0.63."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo con mRMR (GLVQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para entrenar los modelos usando los datos que han reducido su número de instancias usando GLVQ, se define una nueva función que no use validación cruzada debido a que el dataset cuenta únicamente con dos instancias, que son los prototipos obtenidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_naive_bayes(X, y, test_data, columns_to_keep):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    print(\"Dimensiones de los conjuntos:\")\n",
    "    print(f\"Conjunto de entrenamiento: {X_train.shape}, {y_train.shape}\")\n",
    "    print(f\"Conjunto de prueba: {X_test.shape}, {y_test.shape}\")\n",
    "\n",
    "    model = GaussianNB()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    accuracy = model.score(X_test, y_test)\n",
    "    print(f\"Precisión en el conjunto de entrenamiento: {accuracy:.2f}\")\n",
    "\n",
    "    X_test_final = test_data[columns_to_keep]\n",
    "    y_test_final = test_data['Class']\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    for col in ['Amount', 'Time']:\n",
    "        if col in X_test_final.columns:\n",
    "            X_test_final[col] = scaler.fit_transform(X_test_final[[col]])\n",
    "\n",
    "    print(y_test_final.value_counts())\n",
    "\n",
    "    y_pred = model.predict(X_test_final)\n",
    "\n",
    "    conf_matrix = confusion_matrix(y_test_final, y_pred)\n",
    "    report = classification_report(y_test_final, y_pred, target_names=['Correctas', 'Fraudulentas'])\n",
    "\n",
    "    print(\"Matriz de confusión:\")\n",
    "    print(conf_matrix)\n",
    "    print(\"\\nReporte de Clasificación:\")\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluación con mRMR GLVQ ---\n",
      "Dimensiones de los conjuntos:\n",
      "Conjunto de entrenamiento: (1, 10), (1,)\n",
      "Conjunto de prueba: (1, 10), (1,)\n",
      "Precisión en el conjunto de entrenamiento: 0.00\n",
      "Class\n",
      "0    28432\n",
      "1       49\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión:\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Correctas       1.00      1.00      1.00     28432\n",
      "Fraudulentas       0.00      0.00      0.00        49\n",
      "\n",
      "    accuracy                           1.00     28481\n",
      "   macro avg       0.50      0.50      0.50     28481\n",
      "weighted avg       1.00      1.00      1.00     28481\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\Desktop\\Apuntes\\Máster\\Minería de datos-Preprocesamiento y Clasificacion\\Practica\\dos\\PracticaMineriaDatos\\.venv\\Lib\\site-packages\\sklearn\\naive_bayes.py:513: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "c:\\Users\\Usuario\\Desktop\\Apuntes\\Máster\\Minería de datos-Preprocesamiento y Clasificacion\\Practica\\dos\\PracticaMineriaDatos\\.venv\\Lib\\site-packages\\sklearn\\naive_bayes.py:514: RuntimeWarning: divide by zero encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "c:\\Users\\Usuario\\Desktop\\Apuntes\\Máster\\Minería de datos-Preprocesamiento y Clasificacion\\Practica\\dos\\PracticaMineriaDatos\\.venv\\Lib\\site-packages\\sklearn\\naive_bayes.py:514: RuntimeWarning: invalid value encountered in subtract\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_13428\\1184420830.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test_final[col] = scaler.fit_transform(X_test_final[[col]])\n",
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_13428\\1184420830.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test_final[col] = scaler.fit_transform(X_test_final[[col]])\n",
      "c:\\Users\\Usuario\\Desktop\\Apuntes\\Máster\\Minería de datos-Preprocesamiento y Clasificacion\\Practica\\dos\\PracticaMineriaDatos\\.venv\\Lib\\site-packages\\sklearn\\naive_bayes.py:513: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "c:\\Users\\Usuario\\Desktop\\Apuntes\\Máster\\Minería de datos-Preprocesamiento y Clasificacion\\Practica\\dos\\PracticaMineriaDatos\\.venv\\Lib\\site-packages\\sklearn\\naive_bayes.py:514: RuntimeWarning: divide by zero encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "c:\\Users\\Usuario\\Desktop\\Apuntes\\Máster\\Minería de datos-Preprocesamiento y Clasificacion\\Practica\\dos\\PracticaMineriaDatos\\.venv\\Lib\\site-packages\\sklearn\\naive_bayes.py:514: RuntimeWarning: invalid value encountered in subtract\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "c:\\Users\\Usuario\\Desktop\\Apuntes\\Máster\\Minería de datos-Preprocesamiento y Clasificacion\\Practica\\dos\\PracticaMineriaDatos\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Usuario\\Desktop\\Apuntes\\Máster\\Minería de datos-Preprocesamiento y Clasificacion\\Practica\\dos\\PracticaMineriaDatos\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Usuario\\Desktop\\Apuntes\\Máster\\Minería de datos-Preprocesamiento y Clasificacion\\Practica\\dos\\PracticaMineriaDatos\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "X = df_reduce_mrmr_instances_GLVQ.drop(columns=['Class'])\n",
    "y = df_reduce_mrmr_instances_GLVQ['Class']\n",
    "\n",
    "print(\"\\n--- Evaluación con mRMR GLVQ ---\")\n",
    "train_and_evaluate_naive_bayes(X, y, test_data, columns_to_keep_mrmr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando se reducen las instancias con GLVQ se observa que nunca se predice la clase fraudulenta. Esto es debido a que GaussianNB depende de supuestos estadísticos como normalidad y varianza, por lo que al trabajar simplemente con un prototipo de cada clase, no es capaz de distinguir claramente las clases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo con RFC (GLVQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluación con RFC GLVQ ---\n",
      "Dimensiones de los conjuntos:\n",
      "Conjunto de entrenamiento: (1, 10), (1,)\n",
      "Conjunto de prueba: (1, 10), (1,)\n",
      "Precisión en el conjunto de entrenamiento: 0.00\n",
      "Class\n",
      "0    28432\n",
      "1       49\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión:\n",
      "[[28432     0]\n",
      " [   49     0]]\n",
      "\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Correctas       1.00      1.00      1.00     28432\n",
      "Fraudulentas       0.00      0.00      0.00        49\n",
      "\n",
      "    accuracy                           1.00     28481\n",
      "   macro avg       0.50      0.50      0.50     28481\n",
      "weighted avg       1.00      1.00      1.00     28481\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\Desktop\\Apuntes\\Máster\\Minería de datos-Preprocesamiento y Clasificacion\\Practica\\dos\\PracticaMineriaDatos\\.venv\\Lib\\site-packages\\sklearn\\naive_bayes.py:513: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "c:\\Users\\Usuario\\Desktop\\Apuntes\\Máster\\Minería de datos-Preprocesamiento y Clasificacion\\Practica\\dos\\PracticaMineriaDatos\\.venv\\Lib\\site-packages\\sklearn\\naive_bayes.py:514: RuntimeWarning: divide by zero encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "c:\\Users\\Usuario\\Desktop\\Apuntes\\Máster\\Minería de datos-Preprocesamiento y Clasificacion\\Practica\\dos\\PracticaMineriaDatos\\.venv\\Lib\\site-packages\\sklearn\\naive_bayes.py:514: RuntimeWarning: invalid value encountered in subtract\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "c:\\Users\\Usuario\\Desktop\\Apuntes\\Máster\\Minería de datos-Preprocesamiento y Clasificacion\\Practica\\dos\\PracticaMineriaDatos\\.venv\\Lib\\site-packages\\sklearn\\naive_bayes.py:513: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "c:\\Users\\Usuario\\Desktop\\Apuntes\\Máster\\Minería de datos-Preprocesamiento y Clasificacion\\Practica\\dos\\PracticaMineriaDatos\\.venv\\Lib\\site-packages\\sklearn\\naive_bayes.py:514: RuntimeWarning: divide by zero encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "c:\\Users\\Usuario\\Desktop\\Apuntes\\Máster\\Minería de datos-Preprocesamiento y Clasificacion\\Practica\\dos\\PracticaMineriaDatos\\.venv\\Lib\\site-packages\\sklearn\\naive_bayes.py:514: RuntimeWarning: invalid value encountered in subtract\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "c:\\Users\\Usuario\\Desktop\\Apuntes\\Máster\\Minería de datos-Preprocesamiento y Clasificacion\\Practica\\dos\\PracticaMineriaDatos\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Usuario\\Desktop\\Apuntes\\Máster\\Minería de datos-Preprocesamiento y Clasificacion\\Practica\\dos\\PracticaMineriaDatos\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Usuario\\Desktop\\Apuntes\\Máster\\Minería de datos-Preprocesamiento y Clasificacion\\Practica\\dos\\PracticaMineriaDatos\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "X = df_reduce_RFC_instances_GLVQ.drop(columns=['Class'])\n",
    "y = df_reduce_RFC_instances_GLVQ['Class']\n",
    "\n",
    "print(\"\\n--- Evaluación con RFC GLVQ ---\")\n",
    "train_and_evaluate_naive_bayes(X, y, test_data, columns_to_keep_RFC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ocurre lo mismo que con mRMR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusiones\n",
    "\n",
    "En resumen, este es el rendimiento obtenido con los modelos GaussianNB entrenados con diferentes conjuntos de datos:\n",
    "\n",
    "| Datos                       | Precision fraudulentas | Recall fraudulentas | F1-score fraudulentas |\n",
    "|-----------------------------|------------------------|---------------------|-----------------------|\n",
    "| Dataset completo             | 0.05                   | 0.84                | 0.10                  |\n",
    "| mRMR                         | 0.06                   | 0.78                | 0.11                  |\n",
    "| RFC                          | 0.13                   | 0.88                | 0.23                  |\n",
    "| mRMR+clusterCentroids        | 0.00                   | 0.98                | 0.00                  |\n",
    "| RFC+clusterCentroids_soft    | 0.49                   | 0.84                | 0.62                  |\n",
    "| RFC+clusterCentroids_hard    | 0.50                   | 0.84                | 0.63                  |\n",
    "| mRMR+GLVQ                    | 0.00                   | 0.00                | 0.00                  |\n",
    "| RFC+GLVQ                     | 0.00                   | 0.00                | 0.00                  |\n",
    "\n",
    "Se observa que RFC es la técnica de reducción de características que mejor ha funcionado en este caso, además, al combinarla con la reducción de instancias con clusterCentroids con el método de hard de voto se ha logrado el mejor rendimiento con Naive-Bayes, seguido muy de cerca por clusterCentroids con el método soft de voto. El rendimiento es algo bajo, probablemente debido a la simplicidad de Naive-Bayes y las características del dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
