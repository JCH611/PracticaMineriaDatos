{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble: Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import f1_score, accuracy_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a pobar usando Gradient Boosting y para ello vamos a usar las tres técnicas de características y de reducción de instancia que mejor resultado nos ha dado que son:\n",
    "- mrMr con centroides hard\n",
    "- RFC con centroides soft\n",
    "- RFC con centroides hard\n",
    "\n",
    "Se usa Friedman como criterio para medir la calidad de la particición."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    \"reduce_mrmr_instances_hard\": pd.read_csv('./data/df_reduce_mrmr_instances_hard.csv'),\n",
    "    \"reduce_RFC_instances\": pd.read_csv('./data/df_reduce_RFC_instances.csv'),\n",
    "    \"reduce_RFC_instances_hard\": pd.read_csv('./data/df_reduce_RFC_instances_hard.csv'),\n",
    "    \"test_data\" : pd.read_csv('./data/test_data.csv')    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joses\\AppData\\Local\\Temp\\ipykernel_14116\\1107825650.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x_reduced['Amount'] = scaler.fit_transform(x_reduced[['Amount']])\n",
      "C:\\Users\\joses\\AppData\\Local\\Temp\\ipykernel_14116\\1107825650.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x_reduced['Time'] = scaler.fit_transform(x_reduced[['Time']])\n"
     ]
    }
   ],
   "source": [
    "# Seleccionamos los datos de prueba del conjunto de datos\n",
    "data_prueba = datasets['test_data']\n",
    "\n",
    "# Separar las características (X) de la variable objetivo (y)\n",
    "x = data_prueba.drop(columns=['Class'])\n",
    "y_test_total = data_prueba['Class']\n",
    "\n",
    "# Filtramos las columnas relevantes según mRMR\n",
    "columns_to_keep = ['V17', 'Time', 'Amount', 'V25', 'V20', 'V7', 'V13', 'V22', 'V19', 'V23']\n",
    "x_reduced = x[columns_to_keep]\n",
    "\n",
    "# Crear el scaler para normalizar los datos\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalizamos las columnas seleccionadas\n",
    "x_reduced['Amount'] = scaler.fit_transform(x_reduced[['Amount']])\n",
    "x_reduced['Time'] = scaler.fit_transform(x_reduced[['Time']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "0    28432\n",
      "1       49\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Cogemos los datos de test y les eliminamos las cracterísticas que no necesitamos\n",
    "X = data_prueba.drop(columns=['Class'])\n",
    "y_test_final = data_prueba['Class']\n",
    "### Version con RandomForestClassifier\n",
    "columns_to_keep_RFC = ['V17', 'V16', 'V12', 'V14', 'V11', 'V10', 'V9', 'V4', 'V18', 'V7']\n",
    "X_reduce_RFC = X[columns_to_keep_RFC]\n",
    "\n",
    "print(y_test_final.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting con RFC clusterCentroids_hard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones de los conjuntos:\n",
      "Conjunto de entrenamiento: (708, 10), (708,)\n",
      "Conjunto de prueba: (178, 10), (178,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joses\\miniconda3\\envs\\pre_procesamiento\\Lib\\site-packages\\numpy\\ma\\core.py:2881: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros: {'learning_rate': 0.01, 'max_depth': 4, 'max_features': None, 'n_estimators': 100, 'subsample': 0.8}\n",
      "Mejor puntuación de validación cruzada: 0.9336230146838478\n"
     ]
    }
   ],
   "source": [
    "df_reduce_mrmr_instances = datasets[\"reduce_RFC_instances_hard\"]\n",
    "X = df_reduce_mrmr_instances.drop(columns=['Class'])\n",
    "y = df_reduce_mrmr_instances['Class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "print(\"Dimensiones de los conjuntos:\")\n",
    "print(f\"Conjunto de entrenamiento: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Conjunto de prueba: {X_test.shape}, {y_test.shape}\")\n",
    "\n",
    "# Configura el modelo Gradient Boosting\n",
    "gb_model = GradientBoostingClassifier(random_state=0)\n",
    "\n",
    "# Define el rango de hiperparámetros para GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],  # Número de árboles\n",
    "    'learning_rate': [0.01, 0.1, 0.2],  # Tasa de aprendizaje\n",
    "    'max_depth': [3, 4, 5],  # Profundidad máxima de los árboles\n",
    "    'subsample': [0.8, 1.0],  # Fracción de muestras para entrenar cada árbol\n",
    "    'max_features': ['sqrt', 'log2', None]  # Máximo de características consideradas\n",
    "}\n",
    "\n",
    "# Configura GridSearchCV para buscar los mejores hiperparámetros\n",
    "grid_search = GridSearchCV(estimator=gb_model, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Ajusta el modelo a los datos de entrenamiento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Evalúa el mejor modelo en los datos de prueba\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Imprime los mejores parámetros y su desempeño\n",
    "print(\"Mejores parámetros:\", grid_search.best_params_)\n",
    "print(\"Mejor puntuación de validación cruzada:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejecutamos para el conjunto de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de Confusión:\n",
      "[[27734   698]\n",
      " [    6    43]]\n",
      "\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Correctas       1.00      0.98      0.99     28432\n",
      "Fraudulentas       0.06      0.88      0.11        49\n",
      "\n",
      "    accuracy                           0.98     28481\n",
      "   macro avg       0.53      0.93      0.55     28481\n",
      "weighted avg       1.00      0.98      0.99     28481\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo en el conjunto de prueba\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_reduce_RFC)\n",
    "test_accuracy = accuracy_score(y_test_total, y_pred)\n",
    "\n",
    "# Calcular la matriz de confusión y el reporte de clasificación\n",
    "conf_matrix = confusion_matrix(y_test_total, y_pred)\n",
    "report = classification_report(y_test_total, y_pred, target_names=['Correctas', 'Fraudulentas'])\n",
    "\n",
    "# Mostrar la matriz de confusión y el reporte\n",
    "print(\"\\nMatriz de Confusión:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"\\nReporte de Clasificación:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting con mrMr clusterCentroids_hard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones de los conjuntos:\n",
      "Conjunto de entrenamiento: (708, 10), (708,)\n",
      "Conjunto de prueba: (178, 10), (178,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joses\\miniconda3\\envs\\pre_procesamiento\\Lib\\site-packages\\numpy\\ma\\core.py:2881: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros: {'learning_rate': 0.2, 'max_depth': 4, 'max_features': 'sqrt', 'n_estimators': 200, 'subsample': 0.8}\n",
      "Mejor puntuación de validación cruzada: 0.9237838377784436\n"
     ]
    }
   ],
   "source": [
    "df_reduce_mrmr_instances = datasets[\"reduce_mrmr_instances_hard\"]\n",
    "X = df_reduce_mrmr_instances.drop(columns=['Class'])\n",
    "y = df_reduce_mrmr_instances['Class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "print(\"Dimensiones de los conjuntos:\")\n",
    "print(f\"Conjunto de entrenamiento: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Conjunto de prueba: {X_test.shape}, {y_test.shape}\")\n",
    "\n",
    "# Configura el modelo Gradient Boosting\n",
    "gb_model = GradientBoostingClassifier(random_state=0)\n",
    "\n",
    "# Define el rango de hiperparámetros para GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],  # Número de árboles\n",
    "    'learning_rate': [0.01, 0.1, 0.2],  # Tasa de aprendizaje\n",
    "    'max_depth': [3, 4, 5],  # Profundidad máxima de los árboles\n",
    "    'subsample': [0.8, 1.0],  # Fracción de muestras para entrenar cada árbol\n",
    "    'max_features': ['sqrt', 'log2', None]  # Máximo de características consideradas\n",
    "}\n",
    "\n",
    "# Configura GridSearchCV para buscar los mejores hiperparámetros\n",
    "grid_search = GridSearchCV(estimator=gb_model, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Ajusta el modelo a los datos de entrenamiento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Imprime los mejores parámetros y su desempeño\n",
    "print(\"Mejores parámetros:\", grid_search.best_params_)\n",
    "print(\"Mejor puntuación de validación cruzada:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejecutamos para el conjunto de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de Confusión:\n",
      "[[26620  1812]\n",
      " [    4    45]]\n",
      "\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Correctas       1.00      0.94      0.97     28432\n",
      "Fraudulentas       0.02      0.92      0.05        49\n",
      "\n",
      "    accuracy                           0.94     28481\n",
      "   macro avg       0.51      0.93      0.51     28481\n",
      "weighted avg       1.00      0.94      0.97     28481\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo en el conjunto de prueba\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(x_reduced)\n",
    "test_accuracy = accuracy_score(y_test_total, y_pred)\n",
    "\n",
    "# Calcular la matriz de confusión y el reporte de clasificación\n",
    "conf_matrix = confusion_matrix(y_test_total, y_pred)\n",
    "report = classification_report(y_test_total, y_pred, target_names=['Correctas', 'Fraudulentas'])\n",
    "\n",
    "# Mostrar la matriz de confusión y el reporte\n",
    "print(\"\\nMatriz de Confusión:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"\\nReporte de Clasificación:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting con RFC clusterCentroids_soft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones de los conjuntos:\n",
      "Conjunto de entrenamiento: (708, 10), (708,)\n",
      "Conjunto de prueba: (178, 10), (178,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joses\\miniconda3\\envs\\pre_procesamiento\\Lib\\site-packages\\numpy\\ma\\core.py:2881: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros: {'learning_rate': 0.01, 'max_depth': 3, 'max_features': None, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Mejor puntuación de validación cruzada: 0.9265408051143741\n"
     ]
    }
   ],
   "source": [
    "df_reduce_RFC_instances = datasets[\"reduce_RFC_instances\"]\n",
    "X = df_reduce_RFC_instances.drop(columns=['Class'])\n",
    "y = df_reduce_RFC_instances['Class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "print(\"Dimensiones de los conjuntos:\")\n",
    "print(f\"Conjunto de entrenamiento: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Conjunto de prueba: {X_test.shape}, {y_test.shape}\")\n",
    "\n",
    "# Configura el modelo Gradient Boosting\n",
    "gb_model = GradientBoostingClassifier(random_state=0)\n",
    "\n",
    "# Define el rango de hiperparámetros para GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],  # Número de árboles\n",
    "    'learning_rate': [0.01, 0.1, 0.2],  # Tasa de aprendizaje\n",
    "    'max_depth': [3, 4, 5],  # Profundidad máxima de los árboles\n",
    "    'subsample': [0.8, 1.0],  # Fracción de muestras para entrenar cada árbol\n",
    "    'max_features': ['sqrt', 'log2', None]  # Máximo de características consideradas\n",
    "}\n",
    "\n",
    "# Configura GridSearchCV para buscar los mejores hiperparámetros\n",
    "grid_search = GridSearchCV(estimator=gb_model, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Ajusta el modelo a los datos de entrenamiento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Imprime los mejores parámetros y su desempeño\n",
    "print(\"Mejores parámetros:\", grid_search.best_params_)\n",
    "print(\"Mejor puntuación de validación cruzada:\", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de Confusión:\n",
      "[[27852   580]\n",
      " [    7    42]]\n",
      "\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Correctas       1.00      0.98      0.99     28432\n",
      "Fraudulentas       0.07      0.86      0.13        49\n",
      "\n",
      "    accuracy                           0.98     28481\n",
      "   macro avg       0.53      0.92      0.56     28481\n",
      "weighted avg       1.00      0.98      0.99     28481\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo en el conjunto de prueba\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_reduce_RFC)\n",
    "test_accuracy = accuracy_score(y_test_total, y_pred)\n",
    "\n",
    "# Calcular la matriz de confusión y el reporte de clasificación\n",
    "conf_matrix = confusion_matrix(y_test_total, y_pred)\n",
    "report = classification_report(y_test_total, y_pred, target_names=['Correctas', 'Fraudulentas'])\n",
    "\n",
    "# Mostrar la matriz de confusión y el reporte\n",
    "print(\"\\nMatriz de Confusión:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"\\nReporte de Clasificación:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost con mrmr instances hard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "Mejores parámetros: {'colsample_bytree': 1.0, 'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.8}\n",
      "Mejor puntuación de validación cruzada: 0.9053672316384181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joses\\miniconda3\\envs\\pre_procesamiento\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [17:34:22] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "df_reduce_RFC_instances = datasets[\"reduce_mrmr_instances_hard\"]\n",
    "X = df_reduce_RFC_instances.drop(columns=['Class'])\n",
    "y = df_reduce_RFC_instances['Class']\n",
    "\n",
    "# Divide los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Modelo base de XGBoost\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", random_state=42)\n",
    "\n",
    "# Definición del grid de hiperparámetros\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Configuración de GridSearchCV con cv=2\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Entrenar GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Obtener los mejores parámetros y el mejor puntaje\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Mejores parámetros:\", best_params)\n",
    "print(\"Mejor puntuación de validación cruzada:\", best_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de Confusión:\n",
      "[[26525  1907]\n",
      " [    5    44]]\n",
      "\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Correctas       1.00      0.93      0.97     28432\n",
      "Fraudulentas       0.02      0.90      0.04        49\n",
      "\n",
      "    accuracy                           0.93     28481\n",
      "   macro avg       0.51      0.92      0.50     28481\n",
      "weighted avg       1.00      0.93      0.96     28481\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo en el conjunto de prueba\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(x_reduced)\n",
    "test_accuracy = accuracy_score(y_test_total, y_pred)\n",
    "\n",
    "# Calcular la matriz de confusión y el reporte de clasificación\n",
    "conf_matrix = confusion_matrix(y_test_total, y_pred)\n",
    "report = classification_report(y_test_total, y_pred, target_names=['Correctas', 'Fraudulentas'])\n",
    "\n",
    "# Mostrar la matriz de confusión y el reporte\n",
    "print(\"\\nMatriz de Confusión:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"\\nReporte de Clasificación:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost con RFC instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "Mejores parámetros: {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200, 'subsample': 1.0}\n",
      "Mejor puntuación de validación cruzada: 0.9237288135593221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joses\\miniconda3\\envs\\pre_procesamiento\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [16:53:31] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "df_reduce_RFC_instances = datasets[\"reduce_RFC_instances\"]\n",
    "X = df_reduce_RFC_instances.drop(columns=['Class'])\n",
    "y = df_reduce_RFC_instances['Class']\n",
    "\n",
    "# Divide los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Modelo base de XGBoost\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", random_state=42)\n",
    "\n",
    "# Definición del grid de hiperparámetros\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Configuración de GridSearchCV con cv=2\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Entrenar GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Obtener los mejores parámetros y el mejor modelo\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Obtener los mejores parámetros y el mejor puntaje\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Mejores parámetros:\", best_params)\n",
    "print(\"Mejor puntuación de validación cruzada:\", best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejecutamos para el conjunto de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de Confusión:\n",
      "[[28033   399]\n",
      " [    7    42]]\n",
      "\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Correctas       1.00      0.99      0.99     28432\n",
      "Fraudulentas       0.10      0.86      0.17        49\n",
      "\n",
      "    accuracy                           0.99     28481\n",
      "   macro avg       0.55      0.92      0.58     28481\n",
      "weighted avg       1.00      0.99      0.99     28481\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo en el conjunto de prueba\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_reduce_RFC)\n",
    "test_accuracy = accuracy_score(y_test_total, y_pred)\n",
    "\n",
    "# Calcular la matriz de confusión y el reporte de clasificación\n",
    "conf_matrix = confusion_matrix(y_test_total, y_pred)\n",
    "report = classification_report(y_test_total, y_pred, target_names=['Correctas', 'Fraudulentas'])\n",
    "\n",
    "# Mostrar la matriz de confusión y el reporte\n",
    "print(\"\\nMatriz de Confusión:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"\\nReporte de Clasificación:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost con RFC hard instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "Mejores parámetros: {'colsample_bytree': 1.0, 'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 50, 'subsample': 0.8}\n",
      "Mejor puntuación de validación cruzada: 0.9237288135593221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joses\\miniconda3\\envs\\pre_procesamiento\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [16:53:47] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "df_reduce_RFC_instances_hard = datasets[\"reduce_RFC_instances_hard\"]\n",
    "X = df_reduce_RFC_instances_hard.drop(columns=['Class'])\n",
    "y = df_reduce_RFC_instances_hard['Class']\n",
    "\n",
    "# Divide los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Modelo base de XGBoost\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", random_state=42)\n",
    "\n",
    "# Definición del grid de hiperparámetros\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Configuración de GridSearchCV con cv=2\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Entrenar GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Obtener los mejores parámetros y el mejor modelo\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "print(\"Mejores parámetros:\", best_params)\n",
    "print(\"Mejor puntuación de validación cruzada:\", best_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejecutamos para el conjunto de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matriz de Confusión:\n",
      "[[27548   884]\n",
      " [    6    43]]\n",
      "\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Correctas       1.00      0.97      0.98     28432\n",
      "Fraudulentas       0.05      0.88      0.09        49\n",
      "\n",
      "    accuracy                           0.97     28481\n",
      "   macro avg       0.52      0.92      0.54     28481\n",
      "weighted avg       1.00      0.97      0.98     28481\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo en el conjunto de prueba\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_reduce_RFC)\n",
    "test_accuracy = accuracy_score(y_test_total, y_pred)\n",
    "\n",
    "# Calcular la matriz de confusión y el reporte de clasificación\n",
    "conf_matrix = confusion_matrix(y_test_total, y_pred)\n",
    "report = classification_report(y_test_total, y_pred, target_names=['Correctas', 'Fraudulentas'])\n",
    "\n",
    "# Mostrar la matriz de confusión y el reporte\n",
    "print(\"\\nMatriz de Confusión:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"\\nReporte de Clasificación:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tabla Comparativa de Modelos**\n",
    "\n",
    "| Modelo                             | Precisión train | Precisión (Fraudes) | Recall (Fraudes) | Balance General                                       |\n",
    "|------------------------------------|------------------|---------------------|------------------|------------------------------------------------------|\n",
    "| **Gradient Boosting con RFC hard** | 0.51             | 0.06               | 0.88             | Buen recall, pero precisión baja para fraudes.       |\n",
    "| **Gradient Boosting con mrMr**     | 0.53             | 0.02               | 0.92             | Alto recall, muchos falsos positivos.                |\n",
    "| **Gradient Boosting con RFC soft** | 0.53            | 0.07               | 0.86             | Equilibrado, mejor que RFC hard en falsos positivos. |\n",
    "| **XGBoost con mrMr hard**          | 0.51             | 0.02               | 0.90             | Prioriza recall, pero demasiados falsos positivos.   |\n",
    "| **XGBoost con RFC instances**      | 0.51             | 0.10               | 0.86             | Mejor equilibrio entre precisión y recall.           |\n",
    "| **XGBoost con RFC hard**           | 0.55             | 0.05               | 0.88             | Similar a Gradient Boosting RFC hard, menos preciso. |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pre_procesamiento",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
